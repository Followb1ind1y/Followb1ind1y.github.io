<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Large-Scale Pretraining with Transformers on Followblindly</title><link>http://localhost:1313/docs/deep-learning/attention-and-transformers/large-scale-pretraining-with-transformers/</link><description>Recent content in Large-Scale Pretraining with Transformers on Followblindly</description><generator>Hugo</generator><language>en-us</language><atom:link href="http://localhost:1313/docs/deep-learning/attention-and-transformers/large-scale-pretraining-with-transformers/index.xml" rel="self" type="application/rss+xml"/></channel></rss>