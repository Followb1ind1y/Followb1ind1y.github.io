<!doctype html><html lang=en-us dir=ltr><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  经典卷积神经网络 （Modern Convolutional Neural Networks）
  #



  LeNet
  #

LeNet 分为卷积层块和全连接层块两个部分。卷积层块里的基本单位是卷积层后接最大池化层：卷积层用来识别图像里的空间模式，如线条和物体局部，之后的最大池化层则用来降低卷积层对位置的敏感性。卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用 



  \(5×5\)

 的窗口，并在输出上使用 sigmoid 激活函数。第一个卷积层输出通道数为 6，第二个卷积层输出通道数则增加到 16。这是因为第二个卷积层比第一个卷积层的输入的高和宽要小，所以增加输出通道使两个卷积层的参数尺寸类似。卷积层块的两个最大池化层的窗口形状均为 
  \(2×2\)

，且步幅为 2。由于池化窗口与步幅形状相同，池化窗口在输入上每次滑动所覆盖的区域互不重叠。
卷积层块的输出形状为(批量大小, 通道, 高, 宽)。当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本 变平（flatten）。也就是说，全连接层的输入形状将变成二维，其中第一维是小批量中的样本，第二维是每个样本变平后的向量表示，且向量长度为通道、高和宽的乘积。全连接层块含 3 个全连接层。它们的输出个数分别是120、84和10，其中 10 为输出的类别个数。




LeNet 代码实现
import torch
import torch.nn as nn

class LeNet(nn.Module):
    def __init__(self):
        super().__init__()
        # input image size 28x28 -> output size = 28-5+1=24x24
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)
        # input size 24x24 -> output size = (24-2+2)/2=12x12
        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)
        # input size 12x12 -> output size = 12-5+1=8x8
        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)
        # after pooling 8x8 -> 4x4
        self.fc1 = nn.Linear(16*4*4, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.sigmoid(self.conv1(x))
        x = self.pool(x)
        x = self.sigmoid(self.conv2(x))
        x = self.pool(x)
        x = x.view(-1, 16 * 4 * 4)
        x = self.sigmoid(self.fc1(x))
        x = self.sigmoid(self.fc2(x))
        x = self.fc3(x)
        return x




  AlexNet
  #

2012年，AlexNet 横空出世。这个模型的名字来源于论文第一作者的姓名 Alex Krizhevsky。AlexNet 使用了 8 层卷积神经网络，并以很大的优势赢得了 ImageNet 2012 图像识别挑战赛。它首次证明了学习到的特征可以超越手工设计的特征，从而一举打破计算机视觉研究的前状。"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="http://localhost:1313/docs/deep-learning/convolutional-neural-networks/modern-convolutional-neural-networks/"><meta property="og:site_name" content="Followblindly"><meta property="og:title" content="Modern Convolutional Neural Networks"><meta property="og:description" content="经典卷积神经网络 （Modern Convolutional Neural Networks） # LeNet # LeNet 分为卷积层块和全连接层块两个部分。卷积层块里的基本单位是卷积层后接最大池化层：卷积层用来识别图像里的空间模式，如线条和物体局部，之后的最大池化层则用来降低卷积层对位置的敏感性。卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用 \(5×5\) 的窗口，并在输出上使用 sigmoid 激活函数。第一个卷积层输出通道数为 6，第二个卷积层输出通道数则增加到 16。这是因为第二个卷积层比第一个卷积层的输入的高和宽要小，所以增加输出通道使两个卷积层的参数尺寸类似。卷积层块的两个最大池化层的窗口形状均为 \(2×2\) ，且步幅为 2。由于池化窗口与步幅形状相同，池化窗口在输入上每次滑动所覆盖的区域互不重叠。
卷积层块的输出形状为(批量大小, 通道, 高, 宽)。当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本 变平（flatten）。也就是说，全连接层的输入形状将变成二维，其中第一维是小批量中的样本，第二维是每个样本变平后的向量表示，且向量长度为通道、高和宽的乘积。全连接层块含 3 个全连接层。它们的输出个数分别是120、84和10，其中 10 为输出的类别个数。
LeNet 代码实现 import torch import torch.nn as nn class LeNet(nn.Module): def __init__(self): super().__init__() # input image size 28x28 -> output size = 28-5+1=24x24 self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) # input size 24x24 -> output size = (24-2+2)/2=12x12 self.pool = nn.AvgPool2d(kernel_size=2, stride=2) # input size 12x12 -> output size = 12-5+1=8x8 self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5) # after pooling 8x8 -> 4x4 self.fc1 = nn.Linear(16*4*4, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) self.sigmoid = nn.Sigmoid() def forward(self, x): x = self.sigmoid(self.conv1(x)) x = self.pool(x) x = self.sigmoid(self.conv2(x)) x = self.pool(x) x = x.view(-1, 16 * 4 * 4) x = self.sigmoid(self.fc1(x)) x = self.sigmoid(self.fc2(x)) x = self.fc3(x) return x AlexNet # 2012年，AlexNet 横空出世。这个模型的名字来源于论文第一作者的姓名 Alex Krizhevsky。AlexNet 使用了 8 层卷积神经网络，并以很大的优势赢得了 ImageNet 2012 图像识别挑战赛。它首次证明了学习到的特征可以超越手工设计的特征，从而一举打破计算机视觉研究的前状。"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><title>Modern Convolutional Neural Networks | Followblindly</title>
<link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=http://localhost:1313/docs/deep-learning/convolutional-neural-networks/modern-convolutional-neural-networks/><link rel=stylesheet href=/book.min.bff4c6870ba26abd815329272c8df8231704f9ac54bee84c3ef1f649e394d14f.css integrity="sha256-v/TGhwuiar2BUyknLI34IxcE+axUvuhMPvH2SeOU0U8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.fc895b99cab727a888eeb7739002fd8c9b5f608f30110b5efe947067e8e61be5.js integrity="sha256-/Ilbmcq3J6iI7rdzkAL9jJtfYI8wEQte/pRwZ+jmG+U=" crossorigin=anonymous></script><link rel=alternate type=application/rss+xml href=http://localhost:1313/docs/deep-learning/convolutional-neural-networks/modern-convolutional-neural-networks/index.xml title=Followblindly></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/As.png alt=Logo class=book-icon><span>Followblindly</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>Python Basics</span><ul><li><a href=/docs/python-basics/python-fundamentals/>Python Fundamentals</a><ul></ul></li><li><input type=checkbox id=section-b0810fa42fa69050cb4968ec00fbf282 class=toggle>
<label for=section-b0810fa42fa69050cb4968ec00fbf282 class="flex justify-between"><a href=/docs/python-basics/leetcode/>Leetcode Notes</a></label><ul><li><a href=/docs/python-basics/leetcode/practice-history/>Practice History</a><ul></ul></li></ul></li></ul></li><li class=book-section-flat><input type=checkbox id=section-7e28d5ac3e9843e0deb580be9504447e class=toggle>
<label for=section-7e28d5ac3e9843e0deb580be9504447e class="flex justify-between"><a role=button>Common Libraries</a></label><ul><li><a href=/docs/common-libraries/numpy/>NumPy</a><ul></ul></li><li><a href=/docs/common-libraries/pandas/>Pandas</a><ul></ul></li><li><a href=/docs/common-libraries/pytorch/>PyTorch</a><ul></ul></li></ul></li><li class=book-section-flat><span>Machine Learning</span><ul><li><a href=/docs/machine-learning/machine-learning-basics/>Machine Learning Basics</a><ul></ul></li><li><a href=/docs/machine-learning/data-preprocessing/>Data Preprocessing</a><ul></ul></li><li><input type=checkbox id=section-89d4dd5d95507b817cf74368af5982ba class=toggle>
<label for=section-89d4dd5d95507b817cf74368af5982ba class="flex justify-between"><a href=/docs/machine-learning/supervised-learning/>Supervised Learning</a></label><ul><li><a href=/docs/machine-learning/supervised-learning/linear-regression/>Linear Regression</a><ul></ul></li><li><a href=/docs/machine-learning/supervised-learning/logistic-regression/>Logistic Regression</a><ul></ul></li></ul></li><li><input type=checkbox id=section-452d9bf73a55e6b3d947afcc89364ff4 class=toggle>
<label for=section-452d9bf73a55e6b3d947afcc89364ff4 class="flex justify-between"><a href=/docs/machine-learning/unsupervised-learning/>Unsupervised Learning</a></label><ul></ul></li><li><a href=/docs/machine-learning/regularization/>Regularization</a><ul></ul></li><li><a href=/docs/machine-learning/optimization/>Optimization</a><ul></ul></li><li><a href=/docs/machine-learning/computational-performance/>Computational Performance</a><ul></ul></li></ul></li><li class=book-section-flat><span>Deep Learning</span><ul><li><a href=/docs/deep-learning/perceptrons-and-neural-network/>Perceptrons and Neural Network</a><ul></ul></li><li><input type=checkbox id=section-d0dd931d60033c220ecd4cd60b7c9170 class=toggle checked>
<label for=section-d0dd931d60033c220ecd4cd60b7c9170 class="flex justify-between"><a href=/docs/deep-learning/convolutional-neural-networks/>Convolutional Neural Networks</a></label><ul><li><a href=/docs/deep-learning/convolutional-neural-networks/modern-convolutional-neural-networks/ class=active>Modern Convolutional Neural Networks</a><ul></ul></li></ul></li><li><input type=checkbox id=section-a3019bfa8037cc33ed6405d1589b6219 class=toggle>
<label for=section-a3019bfa8037cc33ed6405d1589b6219 class="flex justify-between"><a href=/docs/deep-learning/recurrent-neural-networks/>Recurrent Neural Networks</a></label><ul><li><a href=/docs/deep-learning/recurrent-neural-networks/modern-recurrent-neural-networks/>Modern Recurrent Neural Networks</a><ul></ul></li></ul></li><li><input type=checkbox id=section-0a43584c16258b228ae9aa8d70efc320 class=toggle>
<label for=section-0a43584c16258b228ae9aa8d70efc320 class="flex justify-between"><a href=/docs/deep-learning/attention-and-transformers/>Attention and Transformers</a></label><ul><li><a href=/docs/deep-learning/attention-and-transformers/large-scale-pretraining-with-transformers/>Large-Scale Pretraining with Transformers</a><ul></ul></li><li><a href=/docs/deep-learning/attention-and-transformers/modern-large-language-models-copy/>Modern Large Language Models</a><ul></ul></li></ul></li><li><input type=checkbox id=section-92e8358c45c96009753cf4227e9daea8 class=toggle>
<label for=section-92e8358c45c96009753cf4227e9daea8 class="flex justify-between"><a href=/docs/deep-learning/llm-pipelines/>LLM Pipelines</a></label><ul><li><a href=/docs/deep-learning/llm-pipelines/llm-inference-and-deployment/>LLM Inference and Deployment</a><ul></ul></li></ul></li><li><input type=checkbox id=section-92c62e5374862501ed6fa038204a433f class=toggle>
<label for=section-92c62e5374862501ed6fa038204a433f class="flex justify-between"><a href=/docs/deep-learning/generative-models/>Generative Models</a></label><ul></ul></li></ul></li><li class=book-section-flat><input type=checkbox id=section-8b0266d7d6ac3da61ec6acf4e97681ca class=toggle>
<label for=section-8b0266d7d6ac3da61ec6acf4e97681ca class="flex justify-between"><a role=button>Others</a></label><ul><li><a href=/docs/others/interview-preparation-guide/>Interview Preparation Guide</a><ul></ul></li></ul></li></ul><ul><li><a href=/posts/>Blog</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>Modern Convolutional Neural Networks</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><link rel=stylesheet href=/css/prism-one-dark.css><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#lenet><strong>LeNet</strong></a></li><li><a href=#alexnet><strong>AlexNet</strong></a></li><li><a href=#vgg><strong>VGG</strong></a></li><li><a href=#network-in-network-nin><strong>Network in Network (NiN)</strong></a></li><li><a href=#resnet><strong>ResNet</strong></a><ul><li><a href=#residual-block-的结构><strong>Residual Block 的结构</strong></a></li><li><a href=#residual-block-的意义><strong>Residual Block 的意义</strong></a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=经典卷积神经网络-modern-convolutional-neural-networks><strong>经典卷积神经网络 （Modern Convolutional Neural Networks）</strong>
<a class=anchor href=#%e7%bb%8f%e5%85%b8%e5%8d%b7%e7%a7%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c-modern-convolutional-neural-networks>#</a></h1><hr><h2 id=lenet><strong>LeNet</strong>
<a class=anchor href=#lenet>#</a></h2><p>LeNet 分为<strong>卷积层块</strong>和<strong>全连接层块</strong>两个部分。卷积层块里的基本单位是卷积层后接最大池化层：卷积层用来识别图像里的空间模式，如线条和物体局部，之后的最大池化层则用来降低卷积层对位置的敏感性。卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用
<link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><span>\(5×5\)
</span>的窗口，并在输出上使用 <code>sigmoid</code> 激活函数。第一个卷积层输出通道数为 6，第二个卷积层输出通道数则增加到 16。这是因为第二个卷积层比第一个卷积层的输入的高和宽要小，所以增加输出通道使两个卷积层的参数尺寸类似。卷积层块的两个最大池化层的窗口形状均为 <span>\(2×2\)
</span>，且步幅为 2。由于池化窗口与步幅形状相同，池化窗口在输入上每次滑动所覆盖的区域互不重叠。</p><p>卷积层块的输出形状为(批量大小, 通道, 高, 宽)。当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本 <strong>变平（<em>flatten</em>）</strong>。也就是说，<strong>全连接层的输入形状将变成二维</strong>，其中第一维是小批量中的样本，第二维是每个样本变平后的向量表示，且向量长度为通道、高和宽的乘积。全连接层块含 3 个全连接层。它们的输出个数分别是120、84和10，其中 10 为输出的类别个数。</p><div align=center><img src=/images/lenet.png width=200px/></div><ul><li><strong>LeNet 代码实现</strong><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>LeNet</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        <span style=color:#75715e># input image size 28x28 -&gt; output size = 28-5+1=24x24</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>conv1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Conv2d(in_channels<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, out_channels<span style=color:#f92672>=</span><span style=color:#ae81ff>6</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># input size 24x24 -&gt; output size = (24-2+2)/2=12x12</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>pool <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>AvgPool2d(kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># input size 12x12 -&gt; output size = 12-5+1=8x8</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>conv2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Conv2d(in_channels<span style=color:#f92672>=</span><span style=color:#ae81ff>6</span>, out_channels<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># after pooling 8x8 -&gt; 4x4</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>fc1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>16</span><span style=color:#f92672>*</span><span style=color:#ae81ff>4</span><span style=color:#f92672>*</span><span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>120</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>fc2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>120</span>, <span style=color:#ae81ff>84</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>fc3 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>84</span>, <span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>sigmoid <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sigmoid()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>sigmoid(self<span style=color:#f92672>.</span>conv1(x))
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>pool(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>sigmoid(self<span style=color:#f92672>.</span>conv2(x))
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>pool(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> x<span style=color:#f92672>.</span>view(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>16</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>4</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>4</span>)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>sigmoid(self<span style=color:#f92672>.</span>fc1(x))
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>sigmoid(self<span style=color:#f92672>.</span>fc2(x))
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>fc3(x)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> x
</span></span></code></pre></div></li></ul><hr><h2 id=alexnet><strong>AlexNet</strong>
<a class=anchor href=#alexnet>#</a></h2><p>2012年，AlexNet 横空出世。这个模型的名字来源于论文第一作者的姓名 Alex Krizhevsky。AlexNet 使用了 8 层卷积神经网络，并以很大的优势赢得了 ImageNet 2012 图像识别挑战赛。它首次证明了学习到的特征可以超越手工设计的特征，从而一举打破计算机视觉研究的前状。</p><div align=center><img src=/images/alexnet.png width=300px/></div><ul><li><p><strong>AlexNet 设计框架（Architecture）</strong>:</p><ol><li><p><strong>第一，与相对较小的 LeNet 相比，AlexNet 包含 8 层变换，其中有 5 层卷积和 2 层全连接隐藏层，以及 1 个全连接输出层</strong>。AlexNet 第一层中的卷积窗口形状是 <span>\(11×11\)
</span>。因为 ImageNet 中绝大多数图像的高和宽均比 MNIST 图像的高和宽大 10 倍以上，ImageNet 图像的物体占用更多的像素，所以需要更大的卷积窗口来捕获物体。第二层中的卷积窗口形状减小到 <span>\(5×5\)
</span>，之后全采用 <span>\(3×3\)
</span>。此外，第一、第二和第五个卷积层之后都使用了窗口形状为 <span>\(3×3\)
</span>、步幅为 2 的最大池化层。而且，AlexNet 使用的卷积通道数也大于 LeNet 中的卷积通道数数十倍。</p><p>紧接着最后一个卷积层的是两个输出个数为 4096 的全连接层。这两个巨大的全连接层带来将近 1 GB的模型参数。由于早期显存的限制，最早的 AlexNet 使用双数据流的设计使一个 GPU 只需要处理一半模型。幸运的是，显存在过去几年得到了长足的发展，因此通常我们不再需要这样的特别设计了。</p></li><li><p><strong>第二，AlexNet 将 sigmoid 激活函数改成了更加简单的 ReLU 激活函数</strong>。一方面，ReLU 激活函数的计算更简单，例如它并没有 sigmoid 激活函数中的求幂运算。另一方面，ReLU 激活函数在不同的参数初始化方法下使模型更容易训练。这是由于当 sigmoid 激活函数输出极接近 0 或 1 时，这些区域的梯度几乎为 0，从而造成反向传播无法继续更新部分模型参数；而 ReLU 激活函数在正区间的梯度恒为 1。因此，若模型参数初始化不当，sigmoid 函数可能在正区间得到几乎为 0 的梯度，从而令模型无法得到有效训练。</p></li><li><p><strong>第三，AlexNet 通过 丢弃法（<em>dropout</em>）控制全连接层的模型复杂度，而 LeNet 只使用权重衰减</strong>。为了进一步增强数据，AlexNet 的训练循环添加了大量图像增强，例如翻转、裁剪和颜色变化。这使得模型更加健壮，更大的样本量有效地减少了过拟合。</p></li></ol></li><li><p><strong>LeNet 代码实现</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>AlexNet</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>features <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>96</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>11</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>96</span>, <span style=color:#ae81ff>256</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>384</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>384</span>, <span style=color:#ae81ff>384</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>384</span>, <span style=color:#ae81ff>256</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>classifier <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>256</span><span style=color:#f92672>*</span><span style=color:#ae81ff>6</span><span style=color:#f92672>*</span><span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>4096</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Dropout(),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>4096</span>, <span style=color:#ae81ff>4096</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Dropout(),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>4096</span>, <span style=color:#ae81ff>10</span>),
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>features(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> x<span style=color:#f92672>.</span>view(x<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>), <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>classifier(x)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> x
</span></span></code></pre></div></li></ul><hr><h2 id=vgg><strong>VGG</strong>
<a class=anchor href=#vgg>#</a></h2><p><strong>VGG Network</strong> (Simonyan and Zisserman, 2014)的名字来源于论文作者所在的实验室Visual Geometry Group。VGG（Networks Using Blocks） 提出了可以通过<strong>重复使用简单的基础块来构建深度模型</strong>的思路。VGG 的主要特点是<strong>通过堆叠小卷积核和池化层来增加网络深度，从而提升模型的表达能力</strong>。</p><p>CNN 的基本构件是以下的序列。(i) 带有填充的<strong>卷积层</strong>，以保持分辨率；(ii) <strong>非线性层</strong>，如ReLU；(iii) <strong>池化层</strong>，如最大池化，以降低分辨率。这种方法的问题之一是，<strong>空间分辨率下降得相当快</strong>。Simonyan 和 Zisserman 的关键想法是在下采样过程中以 <strong>块（<em>block</em>）</strong> 的形式<strong>在最大池化前使用多个卷积</strong>。他们最初的主要关注点是深层网络还是宽层网络表现更好。例如，连续应用两个 <span>\(3×3\)
</span>卷积和单个 <span>\(5×5\)
</span>卷积触及相同的像素哪个效果更好。在一个相当详细的分析中，他们表明<strong>深层和窄层网络的表现明显优于浅层的同类网络</strong>。这使深度学习走上了追求更深的网络的道路，在典型的应用中，网络层数超过100层。堆叠 <span>\(3×3\)
</span>卷积已经成为后期深度网络的一个黄金标准。</p><p>VGG 块的组成规律是：<strong>连续使用数个相同的填充为 1、窗口形状为 <span>\(3×3\)
</span>的卷积层后接上一个步幅为 2、窗口形状为 <span>\(2×2\)
</span>的最大池化层</strong>。卷积层保持输入的高和宽不变，而池化层则对其减半。</p><p>对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核优于采用大的卷积核，因为可以<strong>增加网络深度来保证学习更复杂的模式</strong>，而且代价还比较小（参数更少）。例如，在 VGG 中，使用了 3 个 <span>\(3×3\)
</span>卷积核来代替 <span>\(7×7\)
</span>卷积核，使用了 2 个 <span>\(3×3\)
</span>卷积核来代替 <span>\(5×5\)
</span>卷积核，这样做的主要目的是在保证具有<strong>相同感知野的条件下</strong>，提升了<strong>网络的深度</strong>，在一定程度上提升了神经网络的效果。</p><div align=center><img src=/images/vgg.svg width=500px/></div><ul><li><strong>VGG 代码实现</strong><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 定义生成 VGG 卷积块的函数</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>make_vgg_block</span>(input_channels, output_channels, num_convs):
</span></span><span style=display:flex><span>    layers <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(num_convs):
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>append(nn<span style=color:#f92672>.</span>Conv2d(input_channels, output_channels, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>append(nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>))
</span></span><span style=display:flex><span>        input_channels <span style=color:#f92672>=</span> output_channels  <span style=color:#75715e># 更新输入通道为当前输出通道</span>
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>append(nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>))  <span style=color:#75715e># 添加池化层</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> nn<span style=color:#f92672>.</span>Sequential(<span style=color:#f92672>*</span>layers)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 动态定义 VGG 模型</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>VGG</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, architecture, num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>features <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_make_features(architecture)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>classifier <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>512</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>7</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>4096</span>), nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>), nn<span style=color:#f92672>.</span>Dropout(),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>4096</span>, <span style=color:#ae81ff>4096</span>), nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>), nn<span style=color:#f92672>.</span>Dropout(),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>4096</span>, num_classes),
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_make_features</span>(self, architecture):
</span></span><span style=display:flex><span>        layers <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> input_channels, output_channels, num_convs <span style=color:#f92672>in</span> architecture:
</span></span><span style=display:flex><span>            layers<span style=color:#f92672>.</span>append(make_vgg_block(input_channels, output_channels, num_convs))
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> nn<span style=color:#f92672>.</span>Sequential(<span style=color:#f92672>*</span>layers)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>features(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>flatten(x, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>classifier(x)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> x
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 定义 VGG 架构 (以 VGG-16 为例)</span>
</span></span><span style=display:flex><span>vgg16_architecture <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>2</span>),     <span style=color:#75715e># Block 1: 3-&gt;64 通道, 2 个卷积层</span>
</span></span><span style=display:flex><span>    (<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>2</span>),   <span style=color:#75715e># Block 2: 64-&gt;128 通道, 2 个卷积层</span>
</span></span><span style=display:flex><span>    (<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>3</span>),  <span style=color:#75715e># Block 3: 128-&gt;256 通道, 3 个卷积层</span>
</span></span><span style=display:flex><span>    (<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>3</span>),  <span style=color:#75715e># Block 4: 256-&gt;512 通道, 3 个卷积层</span>
</span></span><span style=display:flex><span>    (<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>3</span>),  <span style=color:#75715e># Block 5: 512-&gt;512 通道, 3 个卷积层</span>
</span></span><span style=display:flex><span>]
</span></span></code></pre></div></li></ul><hr><h2 id=network-in-network-nin><strong>Network in Network (NiN)</strong>
<a class=anchor href=#network-in-network-nin>#</a></h2><p>如同 LeNet、AlexNet 和 VGG 的设计中所体现的，传统的卷积神经网络通过一系列卷积层和池化层利用 <strong>空间结构（spatial structure）</strong> 提取特征，并通过全连接层对表征进行后处理。然而，随着网络深度的增加，特别是在 AlexNet 和 VGG 中，网络末端的全连接层带来了两个主要问题：</p><ol><li><strong>参数数量庞大</strong>：<ul><li>在网络的最后阶段，通常通过全连接层将特征映射到分类结果。这些全连接层通常含有巨量的参数，容易造成训练过程中的过拟合，并且会大大增加计算资源的消耗。</li></ul></li><li><strong>无法增加非线性</strong>：<ul><li>在传统的卷积神经网络中，卷积层负责从图像中提取局部特征，而全连接层则将这些特征组合成最终的输出。然而，<strong>增加非线性通常依赖于全连接层的引入</strong>，然而<strong>过早地加入全连接层可能会破坏卷积层捕捉到的空间结构信息</strong>，从而影响模型的性能。</li></ul></li></ol><p><strong>网络中的网络（network in network (NiN)）区块</strong> 提供了一个替代方案，能够在一个简单的策略中解决这两个问题。它们是基于一个非常简单的洞察力提出的:</p><ol><li><strong>使用 <span>\(1×1\)
</span>卷积来增加通道激活的局部非线性</strong>：<ul><li>卷积层的输入和输出通常是四维数组（样本，通道，高，宽），而全连接层的输入和输出则通常是二维数组（样本，特征）。如果想在全连接层后再接上卷积层，则需要将全连接层的输出变换为四维。</li><li><span>\(1×1\)
</span>卷积层。它可以看成全连接层，其中<strong>空间维度（高和宽）上的每个元素相当于样本</strong>，<strong>通道相当于特征</strong>。NiN 背后的想法是<strong>在每个像素位置应用一个全连接层</strong>（对于每个高度和宽度）。由此产生的 <span>\(1×1\)
</span>卷积可以被认为是一个<strong>独立作用于每个像素点的全连接层</strong>。</li><li>通过将多个 <span>\(1×1\)
</span>卷积层堆叠，可以<strong>有效地将每个局部区域的激活映射变得更加复杂</strong>，类似于全连接层的作用，但它不依赖于传统的全连接结构，因此避免了参数量爆炸的问题。</li></ul></li></ol><blockquote class="book-hint warning"><p><strong>Note:</strong> 在传统的卷积层中，每个卷积核只会在 <strong>同一通道内</strong> 提取信息。这意味着每个卷积核仅能操作输入特征图的一个通道，<strong>并不会直接与其他通道的特征进行交互</strong>，不同通道间很难实现结合。为了将不同通道的信息结合，<strong>我们通常需要依赖网络中的 全连接层</strong>，尤其是在网络的最后几层。</p><p><strong>1x1卷积改变了这个局限性，它允许在 通道维度 上进行信息融合。</strong> 除此之外 1x1 卷积可以通过增加通道数来提高网络的表达能力，同时也能在较低的计算开销下实现更复杂的特征学习。它通过引入非线性（通常通过ReLU激活）来增加模型的表现力。</p></blockquote><ol start=2><li><strong>使用全局平均池化 (Global Average Pooling, GAP) 来整合特征</strong>：<ul><li>NiN去除了容易造成过拟合的全连接层，将它们<strong>替换为全局平均池化层（即在所有位置上进行求和）</strong>。该池化层通道数量为所需的输出数量。</li><li>全局平均池化是对每个通道的输出进行空间上的平均，得到一个标量值，<strong>最终生成的输出被用来进行分类或其他任务</strong>。</li><li>与传统的最大池化或平均池化不同，GAP 被用作替代全连接层的方案。它不仅有效减少了参数量，还可以在不丢失空间结构信息的情况下将整个图像的空间特征映射整合成最终的类别输出。</li></ul></li></ol><blockquote class="book-hint warning"><p><strong>Note:</strong> 最终的全局平均池化之前，通道数通常会被设置为与分类任务中的类别数量相匹配。每个通道对应一个特征。对于每一个特征图（即每个通道），全局平均池化（GAP）会对该通道中的所有空间位置（即每个像素）进行平均操作。换句话说，<strong>GAP将每个通道的所有像素值压缩成一个数字</strong>。如果网络有 C 个通道，那么输出就是一个 <strong>C-维的向量</strong>。这个向量包含了所有通道的全局信息。这些数值作为网络的输出特征，来进行<strong>类别预测</strong>。</p></blockquote><div align=center><img src=/images/nin.svg width=550px/></div><p>NiN是在AlexNet问世不久后提出的。它们的卷积层设定有类似之处。NiN使用卷积窗口形状分别为 <span>\(11×11\)
</span>、<span>
\(5×5\)
</span>和 <span>\(3×3\)
</span>的卷积层，相应的输出通道数也与 AlexNet 中的一致。每个 NiN 块后接一个步幅为 2、窗口形状为 <span>\(3×3\)
</span>的最大池化层。</p><ul><li><strong>NiN 代码实现</strong><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn.functional <span style=color:#66d9ef>as</span> F
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># NiN Block</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>NiNBlock</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, in_channels, out_channels, kernel_size, stride, padding):
</span></span><span style=display:flex><span>        super(NiNBlock, self)<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>conv1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Conv2d(in_channels, out_channels, kernel_size, stride, padding)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>conv2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Conv2d(out_channels, out_channels, kernel_size, stride, padding)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>conv3 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Conv2d(out_channels, out_channels, kernel_size, stride, padding)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>relu(self<span style=color:#f92672>.</span>conv1(x))
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>relu(self<span style=color:#f92672>.</span>conv2(x))
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>relu(self<span style=color:#f92672>.</span>conv3(x))
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> x
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># NiN Model</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>NiN</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>net <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            NiNBlock(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>96</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>11</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(<span style=color:#ae81ff>3</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>            NiNBlock(<span style=color:#ae81ff>96</span>, <span style=color:#ae81ff>256</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(<span style=color:#ae81ff>3</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>            NiNBlock(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>384</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(<span style=color:#ae81ff>3</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Dropout(<span style=color:#ae81ff>0.5</span>),  <span style=color:#75715e># Dropout for regularization</span>
</span></span><span style=display:flex><span>            NiNBlock(<span style=color:#ae81ff>384</span>, num_classes, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>AdaptiveAvgPool2d((<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>)),  <span style=color:#75715e># Global Average Pooling</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Flatten()  <span style=color:#75715e># Flatten the output for final classification</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>net(x)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> x
</span></span></code></pre></div></li></ul><hr><h2 id=resnet><strong>ResNet</strong>
<a class=anchor href=#resnet>#</a></h2><p>ResNet (Residual Network) 是由微软研究团队提出的深度神经网络架构，其核心思想是通过 <strong>残差模块 (Residual Block)</strong> 解决深度网络中常见的 <strong>梯度消失问题</strong> 和 <strong>退化问题</strong>。ResNet 在 2015 年的 ImageNet 大赛中取得了冠军，是深度学习领域的里程碑模型。</p><hr><h3 id=residual-block-的结构><strong>Residual Block 的结构</strong>
<a class=anchor href=#residual-block-%e7%9a%84%e7%bb%93%e6%9e%84>#</a></h3><ol><li><p><strong>直观理解：</strong></p><ul><li>一个标准的网络层尝试学习一个复杂的映射 <span>\(H(x)\)
</span>。</li><li>Residual Block 则将目标分解为 <span>\(F(x) + x\)
</span>，其中：<ul><li><span>\(F(x) = H(x) - x\)
</span>：<strong>残差，即网络学习的部分</strong>。</li><li><span>\(x\)
</span>：输入，通过跳跃连接直接传递到输出。</li></ul></li></ul><p>这种结构鼓励网络<strong>专注于学习残差 <span>\(F(x)\)
</span></strong>，而非直接学习 <span>\(H(x)\)
</span>。</p></li><li><p><strong>公式表示：</strong> 假设输入为 <span>\(x\)
</span>，Residual Block 的输出为：
<span>\[
y = F(x, \{W_i\}) + x
\]</span></p><ul><li><span>\(F(x, \{W_i\})\)
</span>：通过卷积、Batch Normalization、ReLU 等操作后得到的输出。</li><li><span>\(x\)
</span>：输入，通过跳跃连接直接添加到 <span>\(F(x)\)
</span>。</li><li><span>\(\{W_i\}\)
</span>：Residual Block 中的可学习参数。</li></ul></li></ol><blockquote><p><strong>举个具体例子：</strong> 假设目标映射 <span>\(H(x)\)
</span>是恒等映射（即 <span>\(H(x) = x\)
</span>），如果网络直接学习 <span>\(H(x)\)
</span>，需要每一层的参数精确调整才能接近这个目标；但如果采用残差学习，网络只需学习 <span>\(F(x) = 0\)
</span>，这对优化过程来说非常简单。</p></blockquote><p>如下图所示，设输入为 <span>\(x\)
</span>。假设我们希望学出的理想映射为 <span>\(f(x)\)
</span>，从而作为图中上方激活函数的输入。左图虚线框中的部分需要直接拟合出该映射 <span>\(f(x)\)
</span>，而右图虚线框中的部分则需要拟合出有关恒等映射的残差映射 <span>\(f(x)−x\)
</span>。残差映射在实际中往往更容易优化。当理想映射 <span>\(f(x)\)
</span>极接近于恒等映射时，残差映射也易于捕捉恒等映射的细微波动。图中右图也是 ResNet 的基础块，即<strong>残差块（<em>residual block</em>）</strong>。其中实线承载层输入 <span>\(x\)
</span>加法运算符称为<strong>残差连接（<em>residual connection</em>）</strong>。在残差块中，输入可通过跨层的数据线路更快地向前传播。</p><div align=center><img src=/images/residual-block.svg width=400px/></div><p>ResNet 沿用了 VGG 全 <span>\(3×3\)
</span>卷积层的设计。残差块里首先有 2 个有相同输出通道数的 <span>\(3×3\)
</span>卷积层。每个卷积层后接一个批量归一化层和 ReLU 激活函数。然后我们将输入跳过这两个卷积运算后直接加在最后的 ReLU 激活函数前。这样的设计要求两个卷积层的输出与输入形状一样，从而可以相加。如果想改变通道数，就需要引入一个额外的 <span>\(1×1\)
</span>卷积层来将输入变换成需要的形状后再做相加运算。</p><div align=center><img src=/images/resnet-block.svg width=500px/></div><hr><h3 id=residual-block-的意义><strong>Residual Block 的意义</strong>
<a class=anchor href=#residual-block-%e7%9a%84%e6%84%8f%e4%b9%89>#</a></h3><ol><li><strong>降低学习难度</strong>：<ul><li><strong>直接学习 <span>\(H(x)\)
</span>（输入到输出的完整映射）可能是一个高度复杂的问题</strong>，而学习残差 <span>\(F(x) = H(x) - x\)
</span>相对简单得多。</li><li>在许多实际任务中，输入 <span>\(x\)
</span>与目标 <span>\(H(x)\)
</span><strong>通常是接近的</strong>（例如图像分类任务中，特征提取后的信息不会发生剧烈变化）。</li><li>通过学习残差 <span>\(F(x)\)
</span>，<strong>网络只需关注输入与输出之间的细微差异</strong>，而不必重新建模整个映射。</li></ul></li><li><strong>缓解梯度消失问题：</strong><ul><li>在深度神经网络中，随着层数增加，梯度会因为<strong>多次链式求导而逐渐减小</strong>，最终导致<strong>梯度消失</strong>问题。</li><li>残差连接提供了一条直接路径，使得<strong>梯度能够不经过中间层直接流回前面的层</strong>。这种 “shortcut” 避免了梯度的逐层衰减，缓解了梯度消失问题，<strong>允许更深层的网络训练</strong>。</li><li>数学上，梯度通过残差连接流回时只需求导 <span>\(\frac{\partial y}{\partial x} = 1 + \frac{\partial F(x)}{\partial x}\)
</span>，<strong>即便 <span>\(\frac{\partial F(x)}{\partial x}\)
</span>较小，梯度仍然保留一个恒定值 1</strong>。</li></ul></li><li><strong>解决退化问题：</strong><ul><li>深度网络常面临 <strong>退化问题</strong>：随着网络<strong>层数增加，模型性能可能不升反降</strong>，即便出现过拟合的风险，这种现象依然存在。</li><li>残差连接的设计允许某些层 “跳过”，从而实现恒等映射（identity mapping），如果某些层对任务无用，网络会自动倾向于<strong>学习恒等映射，使这些层的输出等于输入</strong>。这<strong>确保了增加网络深度不会降低性能</strong>。</li></ul></li><li><strong>简化优化问题：</strong><ul><li>从优化角度看，直接拟合复杂的 <span>\(H(x)\)
</span>映射可能存在多个局部极小值，导致优化困难。而拟合残差 <span>\(F(x) = H(x) - x\)
</span>则相当于让网络优化从输入的一个初始解 <span>\(x\)
</span>开始，再逐步修正偏差。</li><li>这将复杂映射分解为多个简单问题，简化了优化过程，使训练更快、更稳定。</li></ul></li><li><strong>提高非线性能力：</strong><ul><li>在传统的网络结构中，每层都直接学习 <span>\(H(x)\)
</span>，如果层数较深，层之间的信息传递可能会导致过平滑的问题（即<strong>较浅层的细节信息在深层被逐渐削弱</strong>）。</li><li>残差学习通过直接连接输入 <span>\(x\)
</span>和输出 <span>\(F(x)\)
</span>，<strong>让浅层信息直接参与深层的输出，避免了过度平滑</strong>，从而提高了网络的表达能力。</li></ul></li></ol><div align=center><img src=/images/resnet18-90.svg width=600px/></div><ul><li><strong>ResNet 代码实现</strong><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torchvision <span style=color:#f92672>import</span> models
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>ResidualBlock</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, in_channels, out_channels, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, downsample<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>        super(ResidualBlock, self)<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>conv1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Conv2d(in_channels, out_channels, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, stride<span style=color:#f92672>=</span>stride, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, bias<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>bn1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>BatchNorm2d(out_channels)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>relu <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>conv2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Conv2d(out_channels, out_channels, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, bias<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>bn2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>BatchNorm2d(out_channels)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>downsample <span style=color:#f92672>=</span> downsample
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        identity <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>downsample <span style=color:#f92672>is</span> <span style=color:#f92672>not</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>            identity <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>downsample(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        out <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>conv1(x)
</span></span><span style=display:flex><span>        out <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>bn1(out)
</span></span><span style=display:flex><span>        out <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>relu(out)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        out <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>conv2(out)
</span></span><span style=display:flex><span>        out <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>bn2(out)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        out <span style=color:#f92672>+=</span> identity
</span></span><span style=display:flex><span>        out <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>relu(out)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> out
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>ResNet18</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>):
</span></span><span style=display:flex><span>        super(ResNet18, self)<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>in_channels <span style=color:#f92672>=</span> <span style=color:#ae81ff>64</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>conv1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>64</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>7</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, bias<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>bn1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>64</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>relu <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>maxpool <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layer1 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_make_layer(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layer2 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_make_layer(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>2</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layer3 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_make_layer(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>2</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layer4 <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_make_layer(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>2</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>avgpool <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>AdaptiveAvgPool2d((<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>fc <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>512</span>, num_classes)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_make_layer</span>(self, out_channels, blocks, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>):
</span></span><span style=display:flex><span>        downsample <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> stride <span style=color:#f92672>!=</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>or</span> self<span style=color:#f92672>.</span>in_channels <span style=color:#f92672>!=</span> out_channels:
</span></span><span style=display:flex><span>            downsample <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>                nn<span style=color:#f92672>.</span>Conv2d(self<span style=color:#f92672>.</span>in_channels, out_channels, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, stride<span style=color:#f92672>=</span>stride, bias<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>),
</span></span><span style=display:flex><span>                nn<span style=color:#f92672>.</span>BatchNorm2d(out_channels),
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        layers <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>append(ResidualBlock(self<span style=color:#f92672>.</span>in_channels, out_channels, stride, downsample))
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>in_channels <span style=color:#f92672>=</span> out_channels
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>1</span>, blocks):
</span></span><span style=display:flex><span>            layers<span style=color:#f92672>.</span>append(ResidualBlock(out_channels, out_channels))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> nn<span style=color:#f92672>.</span>Sequential(<span style=color:#f92672>*</span>layers)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>conv1(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>bn1(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>relu(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>maxpool(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layer1(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layer2(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layer3(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layer4(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>avgpool(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>flatten(x, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>fc(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> x
</span></span></code></pre></div></li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#lenet><strong>LeNet</strong></a></li><li><a href=#alexnet><strong>AlexNet</strong></a></li><li><a href=#vgg><strong>VGG</strong></a></li><li><a href=#network-in-network-nin><strong>Network in Network (NiN)</strong></a></li><li><a href=#resnet><strong>ResNet</strong></a><ul><li><a href=#residual-block-的结构><strong>Residual Block 的结构</strong></a></li><li><a href=#residual-block-的意义><strong>Residual Block 的意义</strong></a></li></ul></li></ul></nav></div></aside></main></body></html>