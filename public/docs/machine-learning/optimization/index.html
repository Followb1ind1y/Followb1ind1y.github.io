<!doctype html><html lang=en-us dir=ltr><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  优化（Optimization）
  #

机器学习和深度学习中的 优化问题（Optimization） 指的是在给定的模型结构和数据集下，通过调整模型的参数，使目标函数（Objective func-tion, or criterion）达到最小化 或最大化的过程。目标函数通常衡量模型预测值与真实值之间的偏差，例如均方误差或交叉熵。在优化过程中，参数更新依赖于目标函数对参数的梯度信息，通过迭代计算逐步逼近最优解。

凸优化（Convex Optimization） 是指目标函数为凸函数的优化问题，凸函数满足以下性质：

任意两点之间的连线上的函数值不会超过这两点的函数值。
数学形式：对于任意  



  \(x_1, x_2 \in \mathbb{R}^n\)

  和  
  \(\theta \in [0, 1]\)

 ，有

  \[
f(\theta x_1 + (1-\theta)x_2) \leq \theta f(x_1) + (1-\theta)f(x_2)
\]


目标函数特点:

单一的全局最优解（Global Minimum）。
常见目标函数形式：二次函数（如  
  \(f(x) = x^2\)

 ）、对数函数、指数函数等。
使用简单的梯度下降或更高效的二阶方法（如牛顿法）即可快速收敛。




非凸优化（Non-Convex Optimization） 非凸优化是指目标函数为非凸函数的优化问题，非凸函数可能存在多个局部最优解（Local Minimum），不满足凸函数的性质。

目标函数特点:

通常为复杂的多峰形状，可能存在多个局部最优解、鞍点甚至平坦区域。
深度学习中的损失函数（如交叉熵、均方误差）大多属于此类。


解决策略:

启发式算法: 使用随机梯度下降（SGD）及其变种（如 Adam、RMSProp）通过随机性帮助跳出局部最优解。
正则化技巧: 添加 L1/L2 正则项以平滑损失函数，减少极值点的数量。
预训练与迁移学习: 通过初始化参数靠近全局最优区域来提高收敛效率。







  基于梯度的优化（Gradient-Based Optimization）
  #

在函数 
  \(y = f(x)\)

 中（其中 
  \(x\)

 和 
  \(y\)

 都是实数），导数 
  \(f'(x)\)

（或者表示为 
  \(\frac{\partial y}{\partial x}\)

） 表示函数在点 
  \(x\)

 处的斜率（Slope）。它描述了输入 
  \(x\)

 的一个微小变化如何引起输出 
  \(y\)

 的相应变化，用以下公式近似表示：

  \[
f(x + \epsilon) \approx f(x) + \epsilon f'(x)
\]


导数在函数优化中非常有用，因为它指示了如何调整 
  \(x\)

 以使 
  \(y\)

 取得小幅改善。例如，当我们沿着导数的反方向移动时，函数值会减小，即：

  \[
f(x - \epsilon \cdot \text{sign}(f'(x))) < f(x)
\]


这种基于导数的优化技术被称为梯度下降法（Gradient Descent）。"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="http://localhost:1313/docs/machine-learning/optimization/"><meta property="og:site_name" content="Followblindly"><meta property="og:title" content="Optimization"><meta property="og:description" content="优化（Optimization） # 机器学习和深度学习中的 优化问题（Optimization） 指的是在给定的模型结构和数据集下，通过调整模型的参数，使目标函数（Objective func-tion, or criterion）达到最小化 或最大化的过程。目标函数通常衡量模型预测值与真实值之间的偏差，例如均方误差或交叉熵。在优化过程中，参数更新依赖于目标函数对参数的梯度信息，通过迭代计算逐步逼近最优解。
凸优化（Convex Optimization） 是指目标函数为凸函数的优化问题，凸函数满足以下性质： 任意两点之间的连线上的函数值不会超过这两点的函数值。 数学形式：对于任意 \(x_1, x_2 \in \mathbb{R}^n\) 和 \(\theta \in [0, 1]\) ，有 \[ f(\theta x_1 + (1-\theta)x_2) \leq \theta f(x_1) + (1-\theta)f(x_2) \] 目标函数特点: 单一的全局最优解（Global Minimum）。 常见目标函数形式：二次函数（如 \(f(x) = x^2\) ）、对数函数、指数函数等。 使用简单的梯度下降或更高效的二阶方法（如牛顿法）即可快速收敛。 非凸优化（Non-Convex Optimization） 非凸优化是指目标函数为非凸函数的优化问题，非凸函数可能存在多个局部最优解（Local Minimum），不满足凸函数的性质。 目标函数特点: 通常为复杂的多峰形状，可能存在多个局部最优解、鞍点甚至平坦区域。 深度学习中的损失函数（如交叉熵、均方误差）大多属于此类。 解决策略: 启发式算法: 使用随机梯度下降（SGD）及其变种（如 Adam、RMSProp）通过随机性帮助跳出局部最优解。 正则化技巧: 添加 L1/L2 正则项以平滑损失函数，减少极值点的数量。 预训练与迁移学习: 通过初始化参数靠近全局最优区域来提高收敛效率。 基于梯度的优化（Gradient-Based Optimization） # 在函数 \(y = f(x)\) 中（其中 \(x\) 和 \(y\) 都是实数），导数 \(f'(x)\) （或者表示为 \(\frac{\partial y}{\partial x}\) ） 表示函数在点 \(x\) 处的斜率（Slope）。它描述了输入 \(x\) 的一个微小变化如何引起输出 \(y\) 的相应变化，用以下公式近似表示： \[ f(x + \epsilon) \approx f(x) + \epsilon f'(x) \] 导数在函数优化中非常有用，因为它指示了如何调整 \(x\) 以使 \(y\) 取得小幅改善。例如，当我们沿着导数的反方向移动时，函数值会减小，即： \[ f(x - \epsilon \cdot \text{sign}(f'(x))) < f(x) \] 这种基于导数的优化技术被称为梯度下降法（Gradient Descent）。"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><title>Optimization | Followblindly</title>
<link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=http://localhost:1313/docs/machine-learning/optimization/><link rel=stylesheet href=/book.min.bff4c6870ba26abd815329272c8df8231704f9ac54bee84c3ef1f649e394d14f.css integrity="sha256-v/TGhwuiar2BUyknLI34IxcE+axUvuhMPvH2SeOU0U8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.a92fa7929255d6b50d4e615691429cf321d08319b585d5de69c2b278f3a48e53.js integrity="sha256-qS+nkpJV1rUNTmFWkUKc8yHQgxm1hdXeacKyePOkjlM=" crossorigin=anonymous></script><link rel=alternate type=application/rss+xml href=http://localhost:1313/docs/machine-learning/optimization/index.xml title=Followblindly></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/As.png alt=Logo class=book-icon><span>Followblindly</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>Python Basics</span><ul><li><a href=/docs/python-basics/python-fundamentals/>Python Fundamentals</a><ul></ul></li><li><input type=checkbox id=section-b0810fa42fa69050cb4968ec00fbf282 class=toggle>
<label for=section-b0810fa42fa69050cb4968ec00fbf282 class="flex justify-between"><a href=/docs/python-basics/leetcode/>Leetcode Notes</a></label><ul><li><a href=/docs/python-basics/leetcode/practice-history/>Practice History</a><ul></ul></li></ul></li></ul></li><li class=book-section-flat><span>Common Libraries</span><ul><li><a href=/docs/common-libraries/numpy/>NumPy</a><ul></ul></li><li><a href=/docs/common-libraries/pandas/>Pandas</a><ul></ul></li><li><a href=/docs/common-libraries/pytorch/>PyTorch</a><ul></ul></li></ul></li><li class=book-section-flat><span>Machine Learning</span><ul><li><a href=/docs/machine-learning/machine-learning-basics/>Machine Learning Basics</a><ul></ul></li><li><a href=/docs/machine-learning/data-preprocessing/>Data Preprocessing</a><ul></ul></li><li><input type=checkbox id=section-89d4dd5d95507b817cf74368af5982ba class=toggle>
<label for=section-89d4dd5d95507b817cf74368af5982ba class="flex justify-between"><a href=/docs/machine-learning/supervised-learning/>Supervised Learning</a></label><ul><li><a href=/docs/machine-learning/supervised-learning/linear-regression/>Linear Regression</a><ul></ul></li><li><a href=/docs/machine-learning/supervised-learning/logistic-regression/>Logistic Regression</a><ul></ul></li></ul></li><li><input type=checkbox id=section-452d9bf73a55e6b3d947afcc89364ff4 class=toggle>
<label for=section-452d9bf73a55e6b3d947afcc89364ff4 class="flex justify-between"><a href=/docs/machine-learning/unsupervised-learning/>Unsupervised Learning</a></label><ul></ul></li><li><a href=/docs/machine-learning/regularization/>Regularization</a><ul></ul></li><li><a href=/docs/machine-learning/optimization/ class=active>Optimization</a><ul></ul></li></ul></li><li class=book-section-flat><span>Deep Learning</span><ul><li><a href=/docs/deep-learning/perceptrons-and-neural-network/>Perceptrons and Neural Network</a><ul></ul></li><li><a href=/docs/deep-learning/convolutional-neural-networks/>Convolutional Neural Networks</a><ul></ul></li><li><input type=checkbox id=section-1d03ca2abc7a4a1911fc57e2cecd1bcf class=toggle>
<label for=section-1d03ca2abc7a4a1911fc57e2cecd1bcf class="flex justify-between"><a href=/docs/deep-learning/computer-vision/>Computer Vision</a></label><ul></ul></li><li><input type=checkbox id=section-92c62e5374862501ed6fa038204a433f class=toggle>
<label for=section-92c62e5374862501ed6fa038204a433f class="flex justify-between"><a href=/docs/deep-learning/generative-models/>Generative Models</a></label><ul></ul></li></ul></li><li class=book-section-flat><input type=checkbox id=section-8b0266d7d6ac3da61ec6acf4e97681ca class=toggle>
<label for=section-8b0266d7d6ac3da61ec6acf4e97681ca class="flex justify-between"><a role=button>Others</a></label><ul></ul></li></ul><ul><li><a href=/posts/>Blog</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>Optimization</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><link rel=stylesheet href=/css/prism-one-dark.css><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#基于梯度的优化gradient-based-optimization><strong>基于梯度的优化（Gradient-Based Optimization）</strong></a><ul><li><a href=#关键概念><strong>关键概念</strong></a></li><li><a href=#全批量梯度下降batch-gradient-descent><strong>全批量梯度下降（Batch Gradient Descent）</strong></a></li><li><a href=#随机梯度下降stochastic-gradient-descent><strong>随机梯度下降（Stochastic Gradient Descent）</strong></a></li><li><a href=#小批量随机梯度下降minibatch-stochastic-gradient-descent><strong>小批量随机梯度下降（Minibatch Stochastic Gradient Descent）</strong></a></li></ul></li><li><a href=#优化深度神经网络的挑战challenges-in-neural-network-optimization><strong>优化深度神经网络的挑战（Challenges in Neural Network Optimization）</strong></a><ul><li><a href=#局部极小值local-minima><strong>局部极小值（Local Minima）</strong></a></li><li><a href=#平坦区域和鞍点plateaus-and-saddle-points><strong>平坦区域和鞍点（Plateaus and Saddle Points）</strong></a></li><li><a href=#梯度爆炸exploding-gradients><strong>梯度爆炸（Exploding Gradients）</strong></a></li><li><a href=#梯度消失long-term-dependencies-and-gradient-vanishing><strong>梯度消失（Long-Term Dependencies and Gradient Vanishing）</strong></a></li><li><a href=#不精确的梯度inexact-gradients><strong>不精确的梯度（Inexact Gradients）</strong></a></li></ul></li><li><a href=#动量momentum><strong>动量（Momentum）</strong></a><ul><li><a href=#momentum-的主要改进与目标问题><strong>Momentum 的主要改进与目标问题</strong></a></li><li><a href=#nesterov-momentum><strong>Nesterov Momentum</strong></a></li></ul></li><li><a href=#参数初始化策略parameter-initialization-strategies><strong>参数初始化策略（Parameter Initialization Strategies）</strong></a><ul><li><a href=#常用初始化方法><strong>常用初始化方法</strong></a></li><li><a href=#现代优化中的初始化改进><strong>现代优化中的初始化改进</strong></a></li></ul></li><li><a href=#algorithms-with-adaptive-learning-rates><strong>Algorithms with Adaptive Learning Rates</strong></a></li><li><a href=#optimization-strategies-and-meta-algorithms><strong>Optimization Strategies and Meta-Algorithms</strong></a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=优化optimization><strong>优化（Optimization）</strong>
<a class=anchor href=#%e4%bc%98%e5%8c%96optimization>#</a></h1><p>机器学习和深度学习中的 <strong>优化问题（Optimization）</strong> 指的是在给定的模型结构和数据集下，通过调整模型的参数，使<strong>目标函数（Objective func-tion, or criterion）达到最小化</strong> 或最大化的过程。目标函数通常衡量模型预测值与真实值之间的偏差，例如均方误差或交叉熵。在优化过程中，参数更新依赖于目标函数对参数的梯度信息，通过迭代计算逐步逼近最优解。</p><ul><li><strong>凸优化（Convex Optimization）</strong> 是指目标函数为凸函数的优化问题，凸函数满足以下性质：<ul><li><strong>任意两点之间的连线上</strong>的函数值不会超过这两点的函数值。</li><li>数学形式：对于任意
<link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><span>\(x_1, x_2 \in \mathbb{R}^n\)
</span>和 <span>\(\theta \in [0, 1]\)
</span>，有
<span>\[
f(\theta x_1 + (1-\theta)x_2) \leq \theta f(x_1) + (1-\theta)f(x_2)
\]</span></li><li><strong>目标函数特点</strong>:<ul><li><strong>单一的全局最优解（Global Minimum）</strong>。</li><li>常见目标函数形式：二次函数（如 <span>\(f(x) = x^2\)
</span>）、对数函数、指数函数等。</li><li>使用简单的梯度下降或更高效的二阶方法（如牛顿法）即可<strong>快速收敛</strong>。</li></ul></li></ul></li><li><strong>非凸优化（Non-Convex Optimization）</strong> 非凸优化是指目标函数为非凸函数的优化问题，非凸函数可能<strong>存在多个局部最优解（Local Minimum）</strong>，不满足凸函数的性质。<ul><li><strong>目标函数特点</strong>:<ul><li>通常为复杂的多峰形状，<strong>可能存在多个局部最优解、鞍点甚至平坦区域</strong>。</li><li><strong>深度学习中的损失函数</strong>（如交叉熵、均方误差）大多属于此类。</li></ul></li><li><strong>解决策略</strong>:<ul><li><strong>启发式算法</strong>: 使用随机梯度下降（SGD）及其变种（如 Adam、RMSProp）通过随机性帮助跳出局部最优解。</li><li><strong>正则化技巧</strong>: 添加 L1/L2 正则项以<strong>平滑损失函数</strong>，减少极值点的数量。</li><li><strong>预训练与迁移学习</strong>: 通过初始化<strong>参数靠近全局最优区域</strong>来提高收敛效率。</li></ul></li></ul></li></ul><hr><h2 id=基于梯度的优化gradient-based-optimization><strong>基于梯度的优化（Gradient-Based Optimization）</strong>
<a class=anchor href=#%e5%9f%ba%e4%ba%8e%e6%a2%af%e5%ba%a6%e7%9a%84%e4%bc%98%e5%8c%96gradient-based-optimization>#</a></h2><p>在函数 <span>\(y = f(x)\)
</span>中（其中 <span>\(x\)
</span>和 <span>\(y\)
</span>都是实数），导数 <span>\(f'(x)\)
</span>（或者表示为 <span>\(\frac{\partial y}{\partial x}\)
</span>） 表示函数在点 <span>\(x\)
</span>处的斜率（Slope）。它描述了输入 <span>\(x\)
</span>的一个<strong>微小变化如何引起输出 <span>\(y\)
</span>的相应变化</strong>，用以下公式近似表示：
<span>\[
f(x + \epsilon) \approx f(x) + \epsilon f'(x)
\]
</span>导数在函数优化中非常有用，因为它指示了如何调整 <span>\(x\)
</span>以使 <span>\(y\)
</span>取得小幅改善。例如，当<strong>我们沿着导数的反方向移动时，函数值会减小</strong>，即：
<span>\[
f(x - \epsilon \cdot \text{sign}(f'(x))) < f(x)
\]
</span>这种基于导数的优化技术被称为<strong>梯度下降法（Gradient Descent）</strong>。</p><div align=center><img src=/images/ML_Basics_03_Gradient_Descent.PNG width=500px/></div><h3 id=关键概念><strong>关键概念</strong>
<a class=anchor href=#%e5%85%b3%e9%94%ae%e6%a6%82%e5%bf%b5>#</a></h3><ol><li><strong>临界点与极值</strong>：<ul><li>当 <span>\(f'(x) = 0\)
</span>时，称为<strong>临界点（Critical points,或者 stationary points）</strong>。</li><li><strong>局部极小值（Local minimum）</strong>：周围点中 <span>\(f(x)\)
</span>最小。</li><li><strong>局部极大值（local maximum）</strong>：周围点中 <span>\(f(x)\)
</span>最大。</li><li><strong>鞍点（Saddle points）</strong>：既非局部极小值也非局部极大值的临界点，其中正交方向的斜率（导数）全部为零（临界点），但<strong>不是函数的局部极值</strong>。在多维空间中，不必具有 0 的特征值才能得到鞍点：只需具有正和负的特征值即可。</li><li><strong>全局极小值（Global minimum）</strong>：函数 <span>\(f(x)\)
</span>在整个<strong>定义域内的最小值</strong>。</li><li><strong>平坦区域（Plateaus）</strong>：平坦区域是指目标函数的梯度几乎为零的区域，网络在这些区域中移动缓慢，几乎没有任何有效的方向引导优化过程。</li><li><strong>悬崖结构区域（Cliffs）</strong>：悬崖结构区域指的是目标函数中梯度变化非常剧烈的区域，即梯度几乎呈现出极为陡峭的下降趋势。在这种区域内，损失函数对于某些参数的变化非常敏感，导致小的参数更新可能引起损失值的剧烈波动。</li></ul><div align=center><img src=/images/ML_Basics_03_Global_Minimum.PNG width=500px/></div></li><li><strong>多维输入优化</strong>：当函数有多个输入（<span>
\(f: \mathbb{R}^n \to \mathbb{R}\)
</span>），优化需要使用<strong>梯度（Gradient）<strong>的概念。梯度是包含</strong>所有偏导数的向量</strong>，定义为：
<span>\[
\nabla_x f(x) = \left[\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \dots, \frac{\partial f}{\partial x_n}\right]
\]
</span>在多维空间中，临界点是所有梯度分量为零的点，即 <span>\(\nabla_x f(x) = 0\)
</span>。</li><li><strong>学习率的选择</strong>：学习率 <span>\(\epsilon\)
</span>决定了每一步更新的幅度，常见选择方式包括：<ul><li>固定的小常数。</li><li>使用线搜索（Line Search），在多种步长中选择目标函数值最小的步长。</li></ul></li><li><strong>梯度下降的收敛</strong>：当梯度的<strong>所有梯度的分量接近零时</strong>，梯度下降算法收敛。实际上，由于优化问题的复杂性，尤其是在深度学习中，我们<strong>通常寻找“足够低”的函数值，而非严格的全局极小值</strong>。</li></ol><hr><h3 id=全批量梯度下降batch-gradient-descent><strong>全批量梯度下降（Batch Gradient Descent）</strong>
<a class=anchor href=#%e5%85%a8%e6%89%b9%e9%87%8f%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8dbatch-gradient-descent>#</a></h3><p>Batch Gradient Descent 是一种优化算法，每次使用整个数据集来计算目标函数的梯度，并基于梯度更新模型参数。这种方法适用于目标函数是所有样本损失的平均值或总和的情况。每次迭代<strong>计算所有训练样本的损失函数梯度</strong>。公式为：
<span>\[
\theta = \theta - \eta \cdot \nabla J(\theta)
\]
</span>其中，<span>
\(\nabla J(\theta)\)
</span>是基于整个数据集的梯度。</p><p><strong>工作流程</strong>一般为：</p><ol><li>初始化模型参数 <span>\(\theta\)
</span>为随机值或设定初值。</li><li>重复以下步骤，直到达到停止条件（如梯度足够小或迭代次数用尽）：<ul><li>计算当前所有样本的目标函数值和梯度 <span>\(\nabla J(\theta)\)</span></li><li>使用梯度更新模型参数：
<span>\[
\theta = \theta - \eta \cdot \nabla J(\theta)
\]</span></li></ul></li><li>输出最终优化的参数。</li></ol><ul><li><strong>优点</strong>：<ol><li><strong>精确性高</strong>：每次更新都基于完整的数据集，提供了目标函数梯度的<strong>精确估计</strong>，使得更新过程稳定可靠。</li><li><strong>容易收敛到局部或全局最优</strong>：因为梯度估计噪声较小，参数<strong>更新方向更明确</strong>。在凸优化问题中，Batch Gradient Descent 的收敛轨迹通常表现为朝向最优解的一条平滑路径，梯度的更新方向明确，不会因为噪声而偏离轨道。但是由于梯度计算使用了整个数据集，优化轨迹通常稳定地沿着梯度方向下降，<strong>容易陷入一个局部最优点或停留在鞍点上。</strong></li></ol></li><li><strong>缺点</strong>：<ol><li><strong>计算资源消耗大</strong>：每次迭代需要对整个数据集计算梯度，在数据量大时计算成本高，不适合分布式或在线训练。</li><li><strong>存储限制</strong>：对于大规模数据集，可能需要更多的内存或存储资源来一次性加载数据。</li><li><strong>收敛速度慢</strong>：尤其在每次迭代中，如果数据集中样本的梯度信息存在冗余，则更新过程可能很低效。</li></ol></li></ul><hr><h3 id=随机梯度下降stochastic-gradient-descent><strong>随机梯度下降（Stochastic Gradient Descent）</strong>
<a class=anchor href=#%e9%9a%8f%e6%9c%ba%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8dstochastic-gradient-descent>#</a></h3><p>SGD是一种优化算法，用于通过梯度下降更新模型参数，以最小化损失函数。它的核心思想是在每次迭代中，<strong>随机选择一个样本计算梯度，而不是使用整个数据集</strong>。这种方式极大地降低了每次更新的计算成本。更新公式为：
<span>\[
\theta = \theta - \eta \cdot \nabla J(\theta; x_i, y_i)
\]</span></p><ul><li><strong>优点</strong>：<ol><li><strong>高效性</strong>：单次梯度计算只涉及一个样本，<strong>计算速度快</strong>，对内存需求低。</li><li><strong>跳出局部最优解</strong>：随机梯度的噪声可以<strong>避免陷入平滑函数中的局部最优点（local minima）</strong>，尤其适合非凸优化问题。</li><li><strong>在线学习能力</strong>：在模型需要不断更新时（如<strong>实时场景</strong>），SGD可以随着数据流实时调整参数。</li></ol></li></ul><blockquote class="book-hint warning"><p><strong>Note：</strong> 随机梯度下降在每次迭代中仅使用一个样本计算梯度，因此梯度估计会带有噪声。这种噪声主要<strong>表现为梯度方向的不确定性</strong>，使得优化过程中的参数更新具有一定的随机性和波动性。随机噪声使得优化路径<strong>不完全按照损失函数表面的梯度方向</strong>前进，而是以一种“抖动”的方式探索参数空间。当优化路径接近某个局部最优点时，全批量梯度可能因所有样本的梯度方向一致而停留在该点；而<strong>随机梯度的波动可能使路径偏离局部最优，继续搜索全局最优解</strong>。</p><p>在深度学习中的目标函数通常具有非凸性质，随机梯度的噪声可以帮助模型训练找到性能更优的解，从而避免陷入次优状态。此外研究表明，在高维空间中，随机梯度的波动尤其有助于突破鞍点，因为鞍点在高维空间中比局部最优点更常见。</p></blockquote><ul><li><strong>缺点</strong>：<ol><li><strong>梯度估计噪声大</strong>：由于每次迭代仅基于单个样本，梯度方向可能<strong>偏离真正的最优方向</strong>，导致优化过程不稳定。</li><li><strong>收敛速度慢</strong>：需要更多迭代次数才能达到较优解，与Batch Gradient Descent相比，<strong>收敛速度可能较慢</strong>。</li><li><strong>对学习率敏感</strong>：<strong>不适当的学习率可能导致震荡或过早停止收敛</strong>，往往可能需要<strong>更小的学习率（ <span>\(\eta \)
</span>）或动态调整以避免振荡</strong>。因此学习率需要仔细调节或动态调整。</li></ol></li></ul><div align=center><img src=/images/batch__stochastic__mini-batch_gradient_descent-Dec-22-2022-04-32-42-4986-AM.png.webp width=700px/></div><hr><h3 id=小批量随机梯度下降minibatch-stochastic-gradient-descent><strong>小批量随机梯度下降（Minibatch Stochastic Gradient Descent）</strong>
<a class=anchor href=#%e5%b0%8f%e6%89%b9%e9%87%8f%e9%9a%8f%e6%9c%ba%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8dminibatch-stochastic-gradient-descent>#</a></h3><p>Minibatch SGD 是一种在每次迭代中使用一小批数据（称为 Minibatch）计算梯度并更新参数的优化方法。它结合了 Batch Gradient Descent 和 Stochastic Gradient Descent 的优点，能够在<strong>计算效率和收敛稳定性之间找到平衡</strong>。</p><ul><li>其<strong>核心工作流程</strong>一般为：<ol><li><strong>数据划分</strong>: 将训练数据集分成若干小批量（Minibatches），每个批次包含 <span>\(m\)
</span>个样本。 Minibatch 大小 <span>\(m \)
</span>一般为 16, 32, 64, 128，根据硬件资源和模型大小调节。</li><li><strong>梯度计算与更新</strong>：对于<strong>每个 Minibatch</strong> ( <span>\(X_{minibatch}, Y_{minibatch} \)
</span>)，计算目标函数在该批次上的梯度并更新参数：
<span>\[
\theta = \theta - \eta \cdot \nabla J(\theta; X_{minibatch}, Y_{minibatch})
\]
</span><strong>较大的 Minibatch 通常需要较大的学习率</strong>。可结合学习率衰减策略（如 Step Decay、Exponential Decay、Warm Restarts）来平衡收敛速度与准确性。</li><li><strong>迭代更新</strong>: 对每个 Minibatch 重复上述步骤，<strong>直到遍历整个数据集（称为一个 epoch）</strong>。根据收敛情况执行多个 epoch。</li></ol></li></ul><blockquote class="book-hint warning"><p><strong>Note</strong>：为了确保梯度估计的无偏性（unbiasedness），Minibatch的样本必须独立随机抽样。如果数据集的自然排列存在相关性（如医疗数据按患者排序），在选择Minibatch前需要对数据集进行随机打乱（shuffle）。所以我们需要在每个 <strong>epoch 开始时随机打乱数据</strong>，避免梯度计算因样本顺序产生偏差。</p></blockquote><ul><li><strong>Minibatch大小的选择</strong>：<ul><li><strong>梯度估计的准确性</strong>：批量越大，梯度估计越精确，但收益递减（标准误差与样本数量的平方根成反比）。</li><li><strong>计算资源限制</strong>：较小的批量可能导致多核硬件或GPU利用率不足；较大的批量需要更多内存。</li><li><strong>硬件优化</strong>：GPU通常在批量大小为2的幂（如32, 64, 128）时性能最佳。</li><li><strong>正则化效果</strong>：较小批量可以引入噪声，具有正则化作用，但需要调整较小的学习率。</li></ul></li></ul><blockquote class="book-hint warning"><p><strong>Note</strong>：Minibatch（小批量）在计算上具有优势（相比于大批量）的原因是，小批量数据（如 32 或 64 个样本）可以被完全加载到 GPU 中进行高效的并行计算。<strong>GPU 的计算效率在处理适量数据时达到峰值</strong>。与此同时，在大批量中需要对更多样本进行梯度计算和聚合，梯度计算过程更复杂，占用更多时间。例如，<strong>矩阵计算的开销随数据规模呈非线性增长</strong>。</p></blockquote><h4 id=训练速度比较><strong>训练速度比较</strong>：
<a class=anchor href=#%e8%ae%ad%e7%bb%83%e9%80%9f%e5%ba%a6%e6%af%94%e8%be%83>#</a></h4><ul><li>SGD 的单次更新虽然快，但更新频率极高，导致整体时间长。</li><li><strong>Minibatch SGD 在更新频率和计算量之间取得了平衡</strong>，往往在<strong>一个 epoch 的整体速度最快</strong>，是实际应用中的首选。</li><li>Batch Gradient Descent 由于每次更新都需要遍历整个数据集，在大规模数据上效率低。</li></ul><hr><h2 id=优化深度神经网络的挑战challenges-in-neural-network-optimization><strong>优化深度神经网络的挑战（Challenges in Neural Network Optimization）</strong>
<a class=anchor href=#%e4%bc%98%e5%8c%96%e6%b7%b1%e5%ba%a6%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e7%9a%84%e6%8c%91%e6%88%98challenges-in-neural-network-optimization>#</a></h2><p>优化深度神经网络面临诸多挑战，因为网络的目标函数通常是非凸函数，即包含多个局部极值点、鞍点和平坦区域等复杂结构。此外，即便是凸优化问题，也会因为高维度和数据特性而复杂化。</p><hr><h3 id=局部极小值local-minima><strong>局部极小值（Local Minima）</strong>
<a class=anchor href=#%e5%b1%80%e9%83%a8%e6%9e%81%e5%b0%8f%e5%80%bclocal-minima>#</a></h3><p>深度神经网络的目标函数（例如分类或回归问题中的损失函数）<strong>通常是非凸的</strong>。非凸函数意味着它可能有<strong>多个局部极小值、鞍点、以及平坦区域</strong>。深度网络的复杂结构使得这些局部极小值的位置和数量变得更加复杂和难以预测。虽然局部极小值可能在低维问题中更常见，但在高维空间中，局部极小值的影响通常被更复杂的平坦区域或鞍点替代。</p><ul><li><strong>局部极小值的影响</strong>：<ol><li><strong>训练停滞</strong>：局部极小值会导致优化算法的停滞，尤其是梯度下降算法。当优化器在一个局部极小值附近时，<strong>梯度变得非常小或几乎为零，参数更新几乎无法继续</strong>，导致训练过程无法继续进行。</li><li><strong>降低训练效率</strong>：即使局部极小值的影响并不完全阻止训练过程，停滞在局部极小值附近也会显著增加训练时间。<strong>优化器可能需要很长时间才能逃脱这些局部极小值</strong>，增加了收敛的时间。</li><li><strong>全局最优解的错失</strong>：如果优化器陷入局部极小值，则无法继续向全局最优解前进。尤其在复杂的神经网络中，局部极小值可能位于一个比较低的损失值附近，因此模型在训练过程中可能会<strong>错过更优的解</strong>。</li></ol></li></ul><hr><h3 id=平坦区域和鞍点plateaus-and-saddle-points><strong>平坦区域和鞍点（Plateaus and Saddle Points）</strong>
<a class=anchor href=#%e5%b9%b3%e5%9d%a6%e5%8c%ba%e5%9f%9f%e5%92%8c%e9%9e%8d%e7%82%b9plateaus-and-saddle-points>#</a></h3><p>深度神经网络包含大量的参数，尤其是深度模型中，每一层的参数都会在目标函数的定义中增加维度。随着维度的增加，非凸优化问题的复杂性大大增加。鞍点和梯度为零的平坦区域在高维空间中更为常见，且它们在这些维度上的“上升”和“下降”趋势很容易相互作用，导致目标函数在这些点附近的行为变得难以预测。鞍点的存在表明，在优化过程中，<strong>目标函数的某些方向上可能是上升的，而其他方向上可能是下降的</strong>。这种局部结构使得优化过程充满不确定性。</p><ul><li><strong>平坦区域和鞍点的影响</strong>：<ol><li><strong>梯度更新变慢</strong>：在平坦区域，梯度接近零，意味着优化算法的<strong>更新非常缓慢</strong>。无论是在平坦区域还是鞍点附近，梯度下降算法（如 SGD）都可能因为梯度过小而在这些区域停滞不前，导致收敛速度变慢，甚至完全停滞。</li><li><strong>优化过程的非稳定性</strong>：鞍点区域的存在导致梯度下降算法可能会**“卡在”某些不理想的位置，无法有效地向全局最优解逼近**。这些点的复杂几何性质使得简单的梯度下降方法无法高效逃离它们，因此可能长时间停留在鞍点区域或平坦区域，无法有效继续优化。</li><li><strong>参数更新难度增加</strong>：在优化过程中，深度神经网络的<strong>参数更新依赖于梯度信息</strong>。如果网络被困在平坦区域或鞍点，它将<strong>无法获得有效的梯度信息</strong>，从而使得参数的更新难以进行。</li></ol></li></ul><hr><h3 id=梯度爆炸exploding-gradients><strong>梯度爆炸（Exploding Gradients）</strong>
<a class=anchor href=#%e6%a2%af%e5%ba%a6%e7%88%86%e7%82%b8exploding-gradients>#</a></h3><p><strong>梯度爆炸（Exploding Gradients）</strong> 是指在反向传播过程中，<strong>梯度值在某些层中异常增大</strong>，导致权重更新时出现非常大的步长，从而导致训练过程中参数的值急剧增大，甚至溢出。</p><ul><li><p><strong>梯度爆炸的原因</strong>：</p><ol><li><strong>链式法则</strong>：在深度神经网络中，反向传播过程通过链式法则计算梯度。当<strong>网络深度较大时，梯度的计算会依赖于多个层的梯度乘积</strong>。如果某些层的梯度值较大，它们会在反向传播过程中不断放大，导致最终梯度值急剧增大，这就造成了梯度爆炸。</li><li><strong>不合理的权重初始化</strong>：如果模型的权重初始化不当（如权重值太大），会使得<strong>每一层的激活值非常大</strong>，导致反向传播时梯度的<strong>放大效应</strong>。</li><li><strong>不适当的激活函数</strong>：某些激活函数，如<strong>ReLU，在特定情况下可能导致梯度爆炸</strong>。特别是当<strong>输入值非常大</strong>时，ReLU激活函数会<strong>直接输出大值</strong>，从而在梯度传播时形成非常大的梯度值。</li></ol></li><li><p><strong>梯度爆炸的影响</strong>：</p><ul><li>梯度爆炸会导致模型参数的值变得异常大，进而导致数值溢出或数值不稳定。具体表现为：训练过程中，损失函数的值出现波动甚至爆炸，模型的参数值可能变得非常大，难以更新，甚至会导致训练停止。</li><li>更严重的是，梯度爆炸可能完全破坏训练过程，导致<strong>模型无法收敛</strong>，并可能使得计算资源的浪费加剧。</li></ul></li></ul><hr><h3 id=梯度消失long-term-dependencies-and-gradient-vanishing><strong>梯度消失（Long-Term Dependencies and Gradient Vanishing）</strong>
<a class=anchor href=#%e6%a2%af%e5%ba%a6%e6%b6%88%e5%a4%b1long-term-dependencies-and-gradient-vanishing>#</a></h3><p>梯度消失问题发生在反向传播（backpropagation）过程中，当网络中的<strong>梯度值在传播时逐渐变小，最终接近零</strong>。由于梯度变得非常小，权重<strong>更新的步伐变得非常缓慢</strong>，导致训练变得非常困难甚至无法收敛。</p><ul><li><p><strong>梯度消失的原因</strong>：</p><ol><li><strong>链式法则</strong>：反向传播算法依赖链式法则来计算梯度，即通过每一层的梯度传递，最终得到损失函数对每个参数的梯度。然而，在深层神经网络或者长序列的网络中，梯度的传递通过多个层或时间步进行叠加。<strong>如果每一层或每一步的梯度值都小于1</strong>（通常是通过激活函数计算的），那么多次乘积会导致<strong>梯度指数级下降</strong>，最终变得非常小。</li><li><strong>激活函数的性质</strong>：常见的激活函数（如sigmoid、tanh）会在其饱和区间（即输入非常大或非常小的时候）将梯度压缩到接近零。（e.g. 当<strong>输入值非常大或非常小时，sigmoid函数的梯度接近于零</strong>，这就导致了反向传播过程中梯度的快速衰减。）</li><li><strong>深层网络和长时间序列</strong>：在深层神经网络（特别是RNN或LSTM）中，层数过多或时间步过长时，梯度必须沿着多个路径传播。这使得梯度在每一步都逐渐缩小，导致梯度几乎无法传递到网络的最早层，尤其是在处理长时间依赖时尤为严重。</li></ol></li><li><p><strong>梯度消失的影响</strong>：</p><ul><li><strong>学习效率低下</strong>：当梯度消失时，网络的参数几乎不更新，尤其是接近输入层的参数。这样，网络在训练过程中无法有效地学习到有用的特征，特别是长时间依赖的特征（例如，RNN中用于记忆先前输入的长期依赖关系）。</li><li><strong>训练停滞或失败</strong>：对于长序列数据，梯度消失会导致模型无法捕捉到远程依赖关系。训练可能会停滞，模型的性能无法提高，导致训练过程失败或收敛到不理想的结果。</li></ul></li></ul><hr><h3 id=不精确的梯度inexact-gradients><strong>不精确的梯度（Inexact Gradients）</strong>
<a class=anchor href=#%e4%b8%8d%e7%b2%be%e7%a1%ae%e7%9a%84%e6%a2%af%e5%ba%a6inexact-gradients>#</a></h3><p>在训练深度神经网络时，不精确的梯度指的是在某些情况下，计算出的梯度<strong>并不是目标函数的准确梯度</strong>，而是经过<strong>近似或估算的</strong>。这种不精确的梯度通常出现在<strong>基于小批量（mini-batch）梯度下降方法的训练过程中</strong>，也可能出现在其他优化方法中，如随机梯度下降（SGD）。这些不精确的梯度可能会影响优化的稳定性和收敛速度。</p><ul><li><p><strong>不精确的梯度的原因</strong>：</p><ul><li><strong>小批量梯度计算</strong>：因为每个小批量的数据量有限，因此计算出的梯度只是目标函数在该小批量数据上的估计值，而<strong>不是在整个训练数据集上的真实梯度</strong>。通常情况下，计算出的梯度<strong>存在一些随机噪声</strong>。这意味着每次梯度更新时，参数并未沿着真正的目标函数梯度方向进行更新，而是被噪声扰动，<strong>导致偏离最优方向</strong>。这种偏差特别是在训练初期更为显著，因为网络的参数尚未经过充分训练，梯度计算更容易受到数据和噪声的影响。</li></ul></li><li><p><strong>不精确的梯度的影响</strong>：</p><ol><li><strong>收敛速度减慢</strong>：因为不精确的梯度会引入噪声和偏差，优化过程会变得不稳定，导致梯度下降算法的收敛速度减慢。具体来说，不精确的梯度可能导致模型参数朝错误的方向更新，甚至陷入局部最优解，而不能快速接近全局最优解。</li><li><strong>过度依赖随机性</strong>：不精确的梯度也使得优化算法过度依赖随机性。虽然这种随机性在一定程度上能够帮助优化过程跳出局部最小值，但<strong>过度的随机性可能导致算法无法有效地找到全局最优解</strong>，并且在不稳定的情况下表现得更加差劲。</li></ol></li></ul><hr><h2 id=动量momentum><strong>动量（Momentum）</strong>
<a class=anchor href=#%e5%8a%a8%e9%87%8fmomentum>#</a></h2><p>Momentum（动量）是一种<strong>基于梯度下降法（Stochastic Gradient Descent）的优化算法改进</strong>，它通过引入动量的概念，在参数更新中融入历史梯度的信息，从而加速优化过程，尤其是在复杂的非凸损失表面中表现出色。<strong>Momentum 通常作为 SGD 的扩展版本使用，可以与 Mini-Batch SGD 结合</strong>。</p><p>Momentum <strong>模仿物理学中的动量</strong>概念：</p><ul><li>在物理中，动量是物体的质量与速度的乘积。物体的运动状态会受到惯性影响，<strong>越大的动量意味着越难改变方向</strong>。</li><li>在优化中，Momentum 会<strong>记录梯度下降的更新方向，并累积这些更新</strong>，以使得参数在一致的方向上更新得更快，而在噪声较大的方向上减少振荡。</li></ul><p>Momentum 基本算法的更新规则如下：
<span>\[
v_t = \gamma v_{t-1} + \eta \nabla J(\theta_{t-1})
\]
</span><span>\[
\theta_t = \theta_{t-1} - v_t
\]</span></p><ol><li><strong>动量项 <span>\(\gamma v_{t-1}\)
</span></strong>：<ul><li>表示上一次更新的方向，具有惯性，当前更新会参考之前的方向。</li><li><span>\(\gamma\)
</span>：动量系数，通常取值在 [0.8, 0.99] 之间。</li></ul></li><li><strong>梯度项 <span>\(\eta \nabla J(\theta_{t-1})\)
</span></strong>：<ul><li>当前的梯度信息，驱动参数向最小值方向移动。</li></ul></li><li><strong>参数更新 <span>\(\theta_t\)
</span></strong>：<ul><li>综合了惯性和当前梯度，更新参数。</li></ul></li></ol><div align=center><img src=/images/vanilla_gd.png width=600px/></div><blockquote class="book-hint warning"><p><strong>Note</strong>：SGD 每次仅使用一个样本或小批量样本来估计梯度，随机梯度的变化使得优化路径在复杂非凸损失表面上具有<strong>探索能力</strong>，有一定概率跳出局部最优解或鞍点。但由于梯度估计不稳定，优化路径可能会呈现<strong>高频振荡</strong>，尤其是在陡峭方向或平坦区域，导致收敛速度较慢。</p><p>Momentum 可以被看作对梯度信息的一种“平滑操作”，减少不必要的小幅度方向变化，优化路径更趋于稳定。但<strong>Momentum 并没有完全消除随机性</strong>。因为梯度<strong>更新仍基于 Minibatch SGD 或 SGD</strong>，随机性依然存在，只是<strong>短期的高频随机波动被抑制</strong>了。</p></blockquote><blockquote><p>对比标准SGD的更新公式：
<span>\[
\theta_t = \theta_{t-1} - \eta \nabla J(\theta_{t-1})
\]</span></p><p>和 Momentum的更新公式：
<span>\[
\theta_t = \theta_{t-1} - \gamma v_{t-1} - \eta \nabla J(\theta_{t-1})
\]</span></p><p>Momentum 保留了 SGD 的随机特性，同时<strong>通过动量的累积减少了噪声对更新路径的干扰</strong>。</p></blockquote><hr><h3 id=momentum-的主要改进与目标问题><strong>Momentum 的主要改进与目标问题</strong>
<a class=anchor href=#momentum-%e7%9a%84%e4%b8%bb%e8%a6%81%e6%94%b9%e8%bf%9b%e4%b8%8e%e7%9b%ae%e6%a0%87%e9%97%ae%e9%a2%98>#</a></h3><p>Momentum 主要针对以下的问题进行优化：</p><ol><li><strong>问题一：收敛速度慢</strong>。在陡峭方向（梯度较大）和较平坦方向（梯度较小）上，SGD 的更新幅度相差较大。在较平坦方向上，<strong>梯度小导致更新缓慢</strong>，而在陡峭方向上，<strong>反复振荡消耗了时间</strong>。<ul><li><strong>Momentum 如何解决</strong>：<ul><li><strong>动量累积历史梯度</strong>：Momentum 会在参数更新时累积之前的梯度信息，形成一个惯性（动量），从而增强优化的方向性。</li><li><strong>加速沿低梯度方向的更新</strong>：对于较平坦的方向，由于<strong>动量项的累积作用，更新步长会逐渐加快</strong>。</li><li><strong>平滑陡峭方向的振荡</strong>：在陡峭方向上，梯度的<strong>更新方向会相互抵消（正负方向交替）</strong>，动量能够有效减少振荡幅度，使得更新更平稳。</li></ul></li></ul></li><li><strong>问题二：局部振荡问题</strong>。在目标函数中接近<strong>局部最优点或鞍点时</strong>，SGD 可能因为随机梯度引入的噪声而<strong>反复振荡，无法稳定收敛</strong>。振荡现象在非凸优化问题中尤为严重，常导致收敛效率低。<ul><li><strong>Momentum 如何解决</strong>：<ul><li><strong>动量的平滑作用</strong>：Momentum 会对当前的梯度值和之前的梯度值进行加权平均，从而减少梯度噪声的影响。</li><li><strong>更新方向的稳定性</strong>：动量累积了一段时间内梯度的总体方向，使得<strong>参数更新不易受到局部梯度噪声的干扰</strong>，避免振荡。</li></ul></li></ul></li><li><strong>问题三：避免陷入局部最优点</strong>。在复杂的高维非凸函数中，优化算法可能会陷入局部最优点，难以找到全局最优解。SGD 由于其更新完全依赖当前梯度，缺乏<strong>全局视角</strong>，更容易陷入局部最优。<ul><li><strong>Momentum 如何解决</strong>：<ul><li><strong>动量的历史信息积累</strong>：Momentum 通过累积多次梯度更新信息，使得优化过程具有<strong>更强的惯性</strong>，能够 <strong>“冲出”某些局部最优点或平坦区域</strong>。</li><li><strong>优化路径的惯性推动</strong>：当优化路径接近局部最优时，<strong>动量机制仍会保持一定的前进趋势</strong>，避免算法在局部区域停滞。</li></ul></li></ul></li></ol><hr><h3 id=nesterov-momentum><strong>Nesterov Momentum</strong>
<a class=anchor href=#nesterov-momentum>#</a></h3><p>Nesterov Momentum（Nesterov加速梯度）是对<strong>传统Momentum方法的一种改进</strong>。它被设计用来加速优化过程并提高收敛速度。其关键思想是，在更新参数之前，预先计算梯度，并且利用当前的 <strong>“预估”位置</strong> 来指导下一步的更新。与传统Momentum方法相比，Nesterov Momentum通常可以获得更好的收敛性能。因为它能够提前“看到”更远的方向，从而更精确地更新参数。它更能利用 <strong>动量的“提前预见”来加速收敛</strong>。具体来说，Nesterov Momentum方法的步骤如下：</p><ol><li><strong>计算预估位置</strong>：在更新之前，首先通过动量项预测出一个“预估”位置。即：
<span>\[
\theta_{\text{temp}} = \theta_t - \gamma v_{t-1}
\]
</span>其中， <span>\(\theta\)
</span>是当前的参数， <span>\(\gamma\)
</span>是动量系数， <span>\(v\)
</span>是上一轮的动量。</li><li><strong>计算梯度</strong>：使用这个预估位置 <span>\(\theta_{\text{temp}}\)
</span>来计算梯度：
<span>\[
\nabla J(\theta_t - \gamma v_{t-1})
\]</span></li><li><strong>更新动量和参数</strong>：然后基于计算得到的梯度，更新动量和参数：
<span>\[
v_t = \gamma v_{t-1} + \eta \nabla J(\theta_t - \mu v_{t-1})
\]
</span><span>\[
\theta_{t+1} = \theta_t - v_t
\]</span></li></ol><div align=center><img src=/images/nesterov.png width=700px/></div><p>Nesterov Momentum的优势在于，它能够在更新之前“预测”到未来的趋势，避免了传统Momentum方法中的<strong>滞后效应</strong>。传统Momentum通过当前的梯度来更新动量，这可能导致参数更新的方向滞后于实际的优化目标。</p><ul><li><p><strong>提前获得信息</strong>：由于在更新参数时使用的是当前动量的预估位置，这使得梯度下降方向更加“前瞻性”，有时比直接使用当前梯度更有效。具体来说，Nesterov Momentum在<strong>梯度计算时</strong>，不是简单地使用当前参数 <span>\(\theta_t\)
</span>，而是使用预估的参数 <span>\(\theta_t - \mu v_{t-1}\)
</span>，即“预测”的位置。</p></li><li><p><strong>减少滞后</strong>：传统Momentum容易受到<strong>过去梯度的影响</strong>，尤其是在损失函数具有不规则曲线时。<strong>例如，当优化过程进入谷底（参数值接近最优解时），新的梯度非常小（接近0），但是动量项会继续沿着之前的方向更新</strong>，这就是所谓的“滞后”现象。由于动量项是对历史梯度的加权平均，<strong>它不会立刻根据当前的梯度信息来调整方向</strong>，而是会继续沿着之前的方向更新参数，直到动量被新的梯度信息所替代。</p><p>Momentum的<strong>本质是“惯性”</strong>，它通过加权之前的梯度来推测更新的方向。<strong>在梯度发生变化的区域，Momentum仍然会继续沿着先前的方向进行更新</strong>。这会导致在梯度发生急剧变化时，动量更新的方向滞后于实际的需求。Nesterov Momentum通过提前估计未来的梯度变化，减少了这种滞后，通常会加速收敛。</p></li></ul><blockquote class="book-hint warning"><p><strong>Note</strong>：在Momentum中，动量是直接根据<strong>当前点的梯度</strong>来更新的，而没有提前预测。</p><p>在Nesterov Momentum中，动量的更新是通过先<strong>计算出一个预估位置</strong>（基于上一步的动量），然后在这个预估位置计算梯度，再利用这个梯度来更新动量（<strong>提前往前走一步</strong>）。这样一来，Nesterov Momentum就“提前”计算了梯度，从而可以更准确地引导下一步的更新。因此，Nesterov Momentum<strong>并不是完全“准确”的梯度</strong>，它是基于当前动量的预测来计算的一个梯度，这个梯度的计算位置是偏向于未来的（即梯度的计算基于预估位置）。</p></blockquote><hr><h2 id=参数初始化策略parameter-initialization-strategies><strong>参数初始化策略（Parameter Initialization Strategies）</strong>
<a class=anchor href=#%e5%8f%82%e6%95%b0%e5%88%9d%e5%a7%8b%e5%8c%96%e7%ad%96%e7%95%a5parameter-initialization-strategies>#</a></h2><p>在深度学习中，<strong>参数初始化</strong>是训练神经网络的重要一步。良好的初始化可以加速收敛，避免梯度消失或梯度爆炸的问题，同时提高最终模型的性能。而不当的初始化则可能导致网络训练缓慢、不稳定，甚至完全无法收敛。</p><ol><li><strong>避免梯度消失与梯度爆炸</strong>：当网络层数较深时，若初始化不当，前向传播中的激活值或反向传播中的梯度可能会指数级地缩小或增大，导致：<ul><li>梯度消失：参数更新几乎停止，无法学习深层特征。</li><li>梯度爆炸：梯度值过大，导致参数更新不稳定。</li></ul></li><li><strong>提高训练速度</strong>：良好的初始化使得激活值和梯度的分布在整个网络中保持适中，从而提高收敛速度。</li><li><strong>避免对称性问题</strong>：若所有权重初始值相同，反向传播时每个神经元将计算出相同的梯度，导致网络无法打破对称性，降低模型的表达能力。<ul><li>初始化需要确保不同的隐藏单元计算不同的函数。</li><li>如果多个隐藏单元具有相同的输入和初始化参数，它们将始终更新为相同的值，丧失多样性。</li><li>随机初始化通常用于打破对称性，避免输入模式或梯度模式丢失。</li></ul></li></ol><blockquote class="book-hint warning"><p><strong>Note</strong>：什么是对称性</p></blockquote><hr><h3 id=常用初始化方法><strong>常用初始化方法</strong>
<a class=anchor href=#%e5%b8%b8%e7%94%a8%e5%88%9d%e5%a7%8b%e5%8c%96%e6%96%b9%e6%b3%95>#</a></h3><h4 id=随机初始化random-initialization><strong>随机初始化（Random Initialization）</strong>
<a class=anchor href=#%e9%9a%8f%e6%9c%ba%e5%88%9d%e5%a7%8b%e5%8c%96random-initialization>#</a></h4><ul><li>通常从高斯分布或均匀分布中随机采样权重。<ul><li><strong>均匀分布</strong>：如 <span>\(W \sim U(-a, a)\)</span></li><li><strong>正态分布</strong>：如 <span>\(W \sim N(0, \sigma^2)\)</span></li></ul></li><li>分布类型对结果影响较小，但分布的 <strong>尺度（scale）</strong> 对优化效果和泛化能力有较大影响。<ul><li><strong>权重过大</strong>：前向传播时，可能导致值爆炸。反向传播时，可能导致梯度爆炸或混沌行为（如RNN）。激活函数饱和，梯度完全丢失。</li><li><strong>权重过小</strong>：信号在前向传播中消失，导致网络无法学习。</li></ul></li></ul><hr><h4 id=xavier-初始化xavier-initialization><strong>Xavier 初始化（Xavier Initialization）</strong>
<a class=anchor href=#xavier-%e5%88%9d%e5%a7%8b%e5%8c%96xavier-initialization>#</a></h4><p>对权重 W 的每个元素，从以下分布中采样：</p><ul><li>均匀分布：
$$ W_{i,j} \sim U\left(-\sqrt{\frac{6}{n_{\text{in}} + n_{\text{out}}}}, \sqrt{\frac{6}{n_{\text{in}} + n_{\text{out}}}}\right) $$</li><li>正态分布：
$$ W_{i,j} \sim N\left(0, \frac{2}{n_{\text{in}} + n_{\text{out}}}\right) $$
其中， n_{\text{in}} 是输入单元数， n_{\text{out}} 是输出单元数。
适用场景：
• 激活函数是 sigmoid 或 tanh 的网络。
• 网络层较浅或中等深度的场景。
• 优点：
• 平衡输入和输出信号的方差，避免激活值和梯度值的极端变化。
• 避免信号在网络中消失或爆炸。
• 缺点：不适用于ReLU类激活函数。</li></ul><hr><h4 id=he-初始化he-initialization><strong>He 初始化（He Initialization）</strong>
<a class=anchor href=#he-%e5%88%9d%e5%a7%8b%e5%8c%96he-initialization>#</a></h4><hr><h3 id=现代优化中的初始化改进><strong>现代优化中的初始化改进</strong>
<a class=anchor href=#%e7%8e%b0%e4%bb%a3%e4%bc%98%e5%8c%96%e4%b8%ad%e7%9a%84%e5%88%9d%e5%a7%8b%e5%8c%96%e6%94%b9%e8%bf%9b>#</a></h3><p>6.1 学习率与初始化的协同
• 初始化与学习率的选择需要协同设计。
• 比如，较大的初始化可能需要较小的学习率，反之亦然。</p><p>6.2 Batch Normalization 的引入
• 批量归一化（Batch Normalization）可以在一定程度上缓解初始化不当带来的问题，使得更宽泛的初始化策略能够被有效利用。</p><p>6.3 自适应优化算法
• 优化算法如 Adam 和 RMSProp 可以通过动态调整学习率，减少对初始化的敏感性。</p><h2 id=algorithms-with-adaptive-learning-rates><strong>Algorithms with Adaptive Learning Rates</strong>
<a class=anchor href=#algorithms-with-adaptive-learning-rates>#</a></h2><h2 id=optimization-strategies-and-meta-algorithms><strong>Optimization Strategies and Meta-Algorithms</strong>
<a class=anchor href=#optimization-strategies-and-meta-algorithms>#</a></h2></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#基于梯度的优化gradient-based-optimization><strong>基于梯度的优化（Gradient-Based Optimization）</strong></a><ul><li><a href=#关键概念><strong>关键概念</strong></a></li><li><a href=#全批量梯度下降batch-gradient-descent><strong>全批量梯度下降（Batch Gradient Descent）</strong></a></li><li><a href=#随机梯度下降stochastic-gradient-descent><strong>随机梯度下降（Stochastic Gradient Descent）</strong></a></li><li><a href=#小批量随机梯度下降minibatch-stochastic-gradient-descent><strong>小批量随机梯度下降（Minibatch Stochastic Gradient Descent）</strong></a></li></ul></li><li><a href=#优化深度神经网络的挑战challenges-in-neural-network-optimization><strong>优化深度神经网络的挑战（Challenges in Neural Network Optimization）</strong></a><ul><li><a href=#局部极小值local-minima><strong>局部极小值（Local Minima）</strong></a></li><li><a href=#平坦区域和鞍点plateaus-and-saddle-points><strong>平坦区域和鞍点（Plateaus and Saddle Points）</strong></a></li><li><a href=#梯度爆炸exploding-gradients><strong>梯度爆炸（Exploding Gradients）</strong></a></li><li><a href=#梯度消失long-term-dependencies-and-gradient-vanishing><strong>梯度消失（Long-Term Dependencies and Gradient Vanishing）</strong></a></li><li><a href=#不精确的梯度inexact-gradients><strong>不精确的梯度（Inexact Gradients）</strong></a></li></ul></li><li><a href=#动量momentum><strong>动量（Momentum）</strong></a><ul><li><a href=#momentum-的主要改进与目标问题><strong>Momentum 的主要改进与目标问题</strong></a></li><li><a href=#nesterov-momentum><strong>Nesterov Momentum</strong></a></li></ul></li><li><a href=#参数初始化策略parameter-initialization-strategies><strong>参数初始化策略（Parameter Initialization Strategies）</strong></a><ul><li><a href=#常用初始化方法><strong>常用初始化方法</strong></a></li><li><a href=#现代优化中的初始化改进><strong>现代优化中的初始化改进</strong></a></li></ul></li><li><a href=#algorithms-with-adaptive-learning-rates><strong>Algorithms with Adaptive Learning Rates</strong></a></li><li><a href=#optimization-strategies-and-meta-algorithms><strong>Optimization Strategies and Meta-Algorithms</strong></a></li></ul></nav></div></aside></main></body></html>