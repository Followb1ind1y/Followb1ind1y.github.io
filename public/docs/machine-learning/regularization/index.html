<!doctype html><html lang=en-us dir=ltr><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  正则化（Regularization）
  #

Regularization 是一种用于防止机器学习模型过拟合（overfitting）的技术。通过在损失函数中添加正则化项（regularization term）等技术，限制模型的复杂度，从而提高模型的泛化能力（generalization ability）。

Note： 正则化通常只在模型的训练（training）阶段生效，不会直接影响 验证（validation）阶段和 推理（inference）阶段。


  参数范数惩罚（Parameter Norm Penalties）
  #

许多正则化方法都是通过向目标函数 



  \(J\)

 添加参数范数惩罚 
  \(\Omega(\theta)\)

 来限制模型（例如神经网络、线性回归或逻辑回归）的容量。我们将正则化的目标函数表示为 
  \(\tilde{J}\)

：

  \[
\tilde{J}(\theta;X,y) = J(\theta;X,y) + \lambda\Omega(\theta) \\
\]


其中 
  \(\lambda \in [0,\infty)\)

 是一个超参数，它加权范数惩罚项 
  \(\Omega\)

 相对于标准目标函数 
  \(J\)

 的相对贡献。将 
  \(\lambda\)

 设置为 0 会导致无正则化，使模型更关注数据拟合。较大的 
  \(\lambda\)

 值对应更多的正则化，从而限制模型复杂度。
当我们的训练算法最小化正则化目标函数 
  \(\tilde{J}\)

 时，它将同时降低训练数据上的原始目标 
  \(J\)

 和参数 
  \(\theta\)

（或参数的某些子集）大小的某些度量。参数范数 
  \(\Omega\)

 的不同选择可能导致不同的解决方案被优先考虑。


  直观理解参数范数正则化的作用
  #



抑制模型复杂度，防止过拟合：

参数范数正则化通过惩罚参数，限制了参数 
  \(\theta\)

  的大小，促使模型学习更小的权重。

大权重通常意味着模型对输入数据的小变化非常敏感，容易过拟合。
小权重会使模型输出更加平滑，对噪声不敏感，泛化能力更强。


这使得模型在高噪声或复杂数据下不会对数据点过度拟合。



大权重的危害：如果某个权重
  \(\theta_i\)

特别大，模型输出就会对输入
  \(x_i\)

的微小变化极为敏感，训练数据的噪声会被放大，导致模型记住了训练集中的噪声（过拟合）。"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="http://localhost:1313/docs/machine-learning/regularization/"><meta property="og:site_name" content="Followblindly"><meta property="og:title" content="Regularization"><meta property="og:description" content="正则化（Regularization） # Regularization 是一种用于防止机器学习模型过拟合（overfitting）的技术。通过在损失函数中添加正则化项（regularization term）等技术，限制模型的复杂度，从而提高模型的泛化能力（generalization ability）。
Note： 正则化通常只在模型的训练（training）阶段生效，不会直接影响 验证（validation）阶段和 推理（inference）阶段。
参数范数惩罚（Parameter Norm Penalties） # 许多正则化方法都是通过向目标函数 \(J\) 添加参数范数惩罚 \(\Omega(\theta)\) 来限制模型（例如神经网络、线性回归或逻辑回归）的容量。我们将正则化的目标函数表示为 \(\tilde{J}\) ：
\[ \tilde{J}(\theta;X,y) = J(\theta;X,y) + \lambda\Omega(\theta) \\ \] 其中 \(\lambda \in [0,\infty)\) 是一个超参数，它加权范数惩罚项 \(\Omega\) 相对于标准目标函数 \(J\) 的相对贡献。将 \(\lambda\) 设置为 0 会导致无正则化，使模型更关注数据拟合。较大的 \(\lambda\) 值对应更多的正则化，从而限制模型复杂度。
当我们的训练算法最小化正则化目标函数 \(\tilde{J}\) 时，它将同时降低训练数据上的原始目标 \(J\) 和参数 \(\theta\) （或参数的某些子集）大小的某些度量。参数范数 \(\Omega\) 的不同选择可能导致不同的解决方案被优先考虑。
直观理解参数范数正则化的作用 # 抑制模型复杂度，防止过拟合：
参数范数正则化通过惩罚参数，限制了参数 \(\theta\) 的大小，促使模型学习更小的权重。 大权重通常意味着模型对输入数据的小变化非常敏感，容易过拟合。 小权重会使模型输出更加平滑，对噪声不敏感，泛化能力更强。 这使得模型在高噪声或复杂数据下不会对数据点过度拟合。 大权重的危害：如果某个权重 \(\theta_i\) 特别大，模型输出就会对输入 \(x_i\) 的微小变化极为敏感，训练数据的噪声会被放大，导致模型记住了训练集中的噪声（过拟合）。"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><title>Regularization | Followblindly</title>
<link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=http://localhost:1313/docs/machine-learning/regularization/><link rel=stylesheet href=/book.min.bff4c6870ba26abd815329272c8df8231704f9ac54bee84c3ef1f649e394d14f.css integrity="sha256-v/TGhwuiar2BUyknLI34IxcE+axUvuhMPvH2SeOU0U8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.670555303dfbb7938e0816360e2c1564f40948efda7b217bb34a969fae5e3801.js integrity="sha256-ZwVVMD37t5OOCBY2DiwVZPQJSO/aeyF7s0qWn65eOAE=" crossorigin=anonymous></script><link rel=alternate type=application/rss+xml href=http://localhost:1313/docs/machine-learning/regularization/index.xml title=Followblindly></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/As.png alt=Logo class=book-icon><span>Followblindly</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>Python Basics</span><ul><li><a href=/docs/python-basics/python-fundamentals/>Python Fundamentals</a><ul></ul></li><li><input type=checkbox id=section-b0810fa42fa69050cb4968ec00fbf282 class=toggle>
<label for=section-b0810fa42fa69050cb4968ec00fbf282 class="flex justify-between"><a href=/docs/python-basics/leetcode/>Leetcode Notes</a></label><ul><li><a href=/docs/python-basics/leetcode/practice-history/>Practice History</a><ul></ul></li></ul></li></ul></li><li class=book-section-flat><input type=checkbox id=section-7e28d5ac3e9843e0deb580be9504447e class=toggle>
<label for=section-7e28d5ac3e9843e0deb580be9504447e class="flex justify-between"><a role=button>Common Libraries</a></label><ul><li><a href=/docs/common-libraries/numpy/>NumPy</a><ul></ul></li><li><a href=/docs/common-libraries/pandas/>Pandas</a><ul></ul></li><li><a href=/docs/common-libraries/pytorch/>PyTorch</a><ul></ul></li></ul></li><li class=book-section-flat><span>Machine Learning</span><ul><li><a href=/docs/machine-learning/machine-learning-basics/>Machine Learning Basics</a><ul></ul></li><li><a href=/docs/machine-learning/data-preprocessing/>Data Preprocessing</a><ul></ul></li><li><input type=checkbox id=section-89d4dd5d95507b817cf74368af5982ba class=toggle>
<label for=section-89d4dd5d95507b817cf74368af5982ba class="flex justify-between"><a href=/docs/machine-learning/supervised-learning/>Supervised Learning</a></label><ul><li><a href=/docs/machine-learning/supervised-learning/linear-regression/>Linear Regression</a><ul></ul></li><li><a href=/docs/machine-learning/supervised-learning/logistic-regression/>Logistic Regression</a><ul></ul></li></ul></li><li><input type=checkbox id=section-452d9bf73a55e6b3d947afcc89364ff4 class=toggle>
<label for=section-452d9bf73a55e6b3d947afcc89364ff4 class="flex justify-between"><a href=/docs/machine-learning/unsupervised-learning/>Unsupervised Learning</a></label><ul></ul></li><li><a href=/docs/machine-learning/regularization/ class=active>Regularization</a><ul></ul></li><li><a href=/docs/machine-learning/optimization/>Optimization</a><ul></ul></li><li><a href=/docs/machine-learning/computational-performance/>Computational Performance</a><ul></ul></li></ul></li><li class=book-section-flat><span>Deep Learning</span><ul><li><a href=/docs/deep-learning/perceptrons-and-neural-network/>Perceptrons and Neural Network</a><ul></ul></li><li><input type=checkbox id=section-d0dd931d60033c220ecd4cd60b7c9170 class=toggle>
<label for=section-d0dd931d60033c220ecd4cd60b7c9170 class="flex justify-between"><a href=/docs/deep-learning/convolutional-neural-networks/>Convolutional Neural Networks</a></label><ul><li><a href=/docs/deep-learning/convolutional-neural-networks/modern-convolutional-neural-networks/>Modern Convolutional Neural Networks</a><ul></ul></li></ul></li><li><input type=checkbox id=section-a3019bfa8037cc33ed6405d1589b6219 class=toggle>
<label for=section-a3019bfa8037cc33ed6405d1589b6219 class="flex justify-between"><a href=/docs/deep-learning/recurrent-neural-networks/>Recurrent Neural Networks</a></label><ul><li><a href=/docs/deep-learning/recurrent-neural-networks/modern-recurrent-neural-networks/>Modern Recurrent Neural Networks</a><ul></ul></li></ul></li><li><input type=checkbox id=section-0a43584c16258b228ae9aa8d70efc320 class=toggle>
<label for=section-0a43584c16258b228ae9aa8d70efc320 class="flex justify-between"><a href=/docs/deep-learning/attention-and-transformers/>Attention and Transformers</a></label><ul><li><a href=/docs/deep-learning/attention-and-transformers/tokenization-and-word-embeddings/>Tokenization and Word Embeddings</a><ul></ul></li><li><a href=/docs/deep-learning/attention-and-transformers/transformer-architecture/>Transformer Architecture</a><ul></ul></li><li><a href=/docs/deep-learning/attention-and-transformers/modern-large-language-models/>Modern LLMs and Pre-Training</a><ul></ul></li><li><a href=/docs/deep-learning/attention-and-transformers/post-training-large-language-models/>Post-training LLMs</a><ul></ul></li><li><a href=/docs/deep-learning/attention-and-transformers/multimodal-large-language-models/>Multimodal Large Language Models</a><ul></ul></li></ul></li><li><input type=checkbox id=section-92e8358c45c96009753cf4227e9daea8 class=toggle>
<label for=section-92e8358c45c96009753cf4227e9daea8 class="flex justify-between"><a href=/docs/deep-learning/llm-pipelines/>LLM Pipelines</a></label><ul><li><a href=/docs/deep-learning/llm-pipelines/llm-hardware-and-model-size/>LLM Hardware and Model Size</a><ul></ul></li><li><a href=/docs/deep-learning/llm-pipelines/large-scale-pretraining-with-transformers/>Large-Scale Pretraining with Transformers</a><ul></ul></li><li><a href=/docs/deep-learning/llm-pipelines/llm-inference-and-deployment/>LLM Inference and Deployment</a><ul></ul></li></ul></li></ul></li><li class=book-section-flat><input type=checkbox id=section-8b0266d7d6ac3da61ec6acf4e97681ca class=toggle>
<label for=section-8b0266d7d6ac3da61ec6acf4e97681ca class="flex justify-between"><a role=button>Others</a></label><ul><li><a href=/docs/others/interview-preparation-guide/>Interview Preparation Guide</a><ul></ul></li></ul></li></ul><ul><li><a href=/posts/>Blog</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>Regularization</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><link rel=stylesheet href=/css/prism-one-dark.css><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#参数范数惩罚parameter-norm-penalties><strong>参数范数惩罚（Parameter Norm Penalties）</strong></a><ul><li><a href=#直观理解参数范数正则化的作用><strong>直观理解参数范数正则化的作用</strong></a></li><li><a href=#l2-正则化l2-regularization><strong>L2 正则化（L2 Regularization）</strong></a></li><li><a href=#l1-正则化l1-regularization><strong>L1 正则化（L1 Regularization）</strong></a></li></ul></li><li><a href=#数据增强dataset-augmentation><strong>数据增强（Dataset Augmentation）</strong></a><ul><li><a href=#图像数据增强><strong>图像数据增强</strong></a></li><li><a href=#文本数据增强><strong>文本数据增强</strong></a></li><li><a href=#时间序列数据增强><strong>时间序列数据增强</strong></a></li></ul></li><li><a href=#噪声注入noise-injection><strong>噪声注入（Noise Injection）</strong></a><ul><li><a href=#常见的噪声注入方法><strong>常见的噪声注入方法</strong></a></li></ul></li><li><a href=#正则化在神经网络中的应用><strong>正则化在神经网络中的应用</strong></a><ul><li><a href=#weight-decay><strong>Weight Decay</strong></a></li><li><a href=#early-stopping><strong>Early Stopping</strong></a></li><li><a href=#dropout><strong>Dropout</strong></a></li><li><a href=#batch-normalization><strong>Batch Normalization</strong></a></li></ul></li><li><a href=#集成学习算法ensemble-methods><strong>集成学习算法（Ensemble Methods）</strong></a></li><li><a href=#对抗训练adversarial-training><strong>对抗训练（Adversarial Training）</strong></a><ul><li><a href=#对抗样本的概念><strong>对抗样本的概念</strong></a></li><li><a href=#对抗训练的过程><strong>对抗训练的过程</strong></a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=正则化regularization><strong>正则化（Regularization）</strong>
<a class=anchor href=#%e6%ad%a3%e5%88%99%e5%8c%96regularization>#</a></h1><p>Regularization 是一种用于<strong>防止机器学习模型过拟合（overfitting）<strong>的技术。通过在损失函数中添加正则化项（regularization term）等技术，限制模型的复杂度，从而</strong>提高模型的泛化能力（generalization ability）</strong>。</p><blockquote class="book-hint warning"><p><strong>Note：</strong> 正则化通常<strong>只在模型的训练（training）阶段生效</strong>，不会直接影响 <strong>验证（validation）阶段</strong>和 <strong>推理（inference）阶段</strong>。</p></blockquote><h2 id=参数范数惩罚parameter-norm-penalties><strong>参数范数惩罚（Parameter Norm Penalties）</strong>
<a class=anchor href=#%e5%8f%82%e6%95%b0%e8%8c%83%e6%95%b0%e6%83%a9%e7%bd%9aparameter-norm-penalties>#</a></h2><p>许多正则化方法都是通过向目标函数
<link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><span>\(J\)
</span>添加参数范数惩罚 <span>\(\Omega(\theta)\)
</span>来限制模型（例如神经网络、线性回归或逻辑回归）的容量。我们将正则化的目标函数表示为 <span>\(\tilde{J}\)
</span>：</p><span>\[
\tilde{J}(\theta;X,y) = J(\theta;X,y) + \lambda\Omega(\theta) \\
\]</span><p>其中 <span>\(\lambda \in [0,\infty)\)
</span>是一个超参数，它加权范数惩罚项 <span>\(\Omega\)
</span>相对于标准目标函数 <span>\(J\)
</span>的相对贡献。将 <span>\(\lambda\)
</span>设置为 0 会导致无正则化，使模型更关注数据拟合。较大的 <span>\(\lambda\)
</span>值对应更多的正则化，从而限制模型复杂度。</p><p>当我们的训练算法最小化正则化目标函数 <span>\(\tilde{J}\)
</span>时，它将同时降低训练数据上的原始目标 <span>\(J\)
</span>和参数 <span>\(\theta\)
</span>（或参数的某些子集）大小的某些度量。参数范数 <span>\(\Omega\)
</span>的不同选择可能导致不同的解决方案被优先考虑。</p><hr><h3 id=直观理解参数范数正则化的作用><strong>直观理解参数范数正则化的作用</strong>
<a class=anchor href=#%e7%9b%b4%e8%a7%82%e7%90%86%e8%a7%a3%e5%8f%82%e6%95%b0%e8%8c%83%e6%95%b0%e6%ad%a3%e5%88%99%e5%8c%96%e7%9a%84%e4%bd%9c%e7%94%a8>#</a></h3><ul><li><p><strong>抑制模型复杂度，防止过拟合</strong>：</p><ul><li>参数范数正则化通过惩罚参数，<strong>限制了参数 <span>\(\theta\)
</span>的大小</strong>，促使模型学习更小的权重。<ul><li><strong>大权重通常意味着模型对输入数据的小变化非常敏感</strong>，容易过拟合。</li><li>小权重会使模型输出<strong>更加平滑，对噪声不敏感</strong>，泛化能力更强。</li></ul></li><li>这使得模型在高噪声或复杂数据下不会对数据点过度拟合。</li></ul></li><li><p><strong>大权重的危害</strong>：如果某个权重<span>
\(\theta_i\)
</span>特别大，模型输出就会对输入<span>
\(x_i\)
</span>的<strong>微小变化极为敏感</strong>，训练数据的<strong>噪声会被放大</strong>，导致<strong>模型记住了训练集中的噪声（过拟合）</strong>。</p></li><li><p><strong>正则化后</strong>：通过惩罚项，正则化会迫使所有<strong>权重尽量小</strong>，让模型输出更平滑，对噪声更鲁棒。</p></li></ul><hr><h3 id=l2-正则化l2-regularization><strong>L2 正则化（L2 Regularization）</strong>
<a class=anchor href=#l2-%e6%ad%a3%e5%88%99%e5%8c%96l2-regularization>#</a></h3><p>L2 正则化（Ridge 正则化）通过在损失函数中<strong>添加权重平方和的惩罚项，限制模型参数的大小</strong>，降低模型复杂度。公式如下：
<span>\[
J(\theta) = Loss(\theta) + \lambda\lVert \theta \rVert_{2}^{2} = Loss(\theta) + \frac{\lambda}{2} \sum_{i=1}^n \theta_i^2
\]</span></p><ul><li><span>\(\lambda\)
</span>：正则化强度，权衡损失函数与正则化项的重要性。</li><li><span>\(\sum_{i=1}^n \theta_i^2\)
</span>：模型权重的 L2 范数（欧几里得范数）。</li><li>正则化项前的 <span>\(\frac{1}{2}\)
</span>是为了后续求导方便。</li></ul><div align=center><img src=/images/l2.png width=400px/></div><p>优化参数 <span>\(\theta\)
</span>时，我们对目标函数 <span>\(J(\theta) \)
</span>关于 <span>\(\theta\)
</span>求偏导：</p><span>\[
\frac{\partial J(\theta)}{\partial \theta} = \nabla J(\theta) + \lambda \theta
\]</span><p>之后将求导结果用于梯度下降法的参数更新规则：</p><span>\[
\theta := \theta - \alpha \left( \nabla J(\theta) + \lambda \theta \right)
\]</span><ul><li><strong>L2 正则化的优点</strong>：<ol><li><strong>平滑性更强</strong>: L2 正则化引入了一个约束，使得参数向量 <span>\(\theta\)
</span>不会无限增大，最终可以提高模型在测试集上的表现。<ul><li>普通模型的参数<span>
\(\theta\)
</span>没有任何约束，模型可能会将一些<strong>特征的权重学得非常大</strong>，导致输出对输入变化非常敏感。</li><li>L2 正则化的模型参数<span>
\(\theta\)
</span>被<strong>约束在一个较小的范围内</strong>，所有权重都会趋于较小的值，模型的<strong>输出曲线更加平滑</strong>。</li></ul></li><li><strong>解决多重共线性问题 降低模型的方差</strong>：<ul><li>当输入特征高度相关时（多重共线性），普通的最小二乘法会导致模型参数的方差非常大。</li><li>参数范数正则化通过惩罚参数的大小，<strong>有效降低了模型的方差</strong>，方差大，意味着模型过拟合。虽然会略微增加模型的偏差（对训练集拟合得稍差），但整体的泛化误差（训练集与测试集之间的误差）会降低。</li></ul></li></ol></li><li><strong>L2 正则化的缺点</strong>:<ul><li><strong>无法实现特征选择</strong>: L2 正则化会将<strong>权重缩小到接近 0</strong>，但不完全为 0，因此模型仍然保留所有特征。</li></ul></li><li><strong>L2 正则化的适用场景</strong>:<ul><li>如果需要提升模型的 <strong>鲁棒性 和 泛化能力</strong>，并且数据是 低维非稀疏数据，优先选择 L2 正则化。</li></ul></li><li><strong>L2 正则化代码实现</strong><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># &lt;--- From scratch ---&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 损失函数：均方误差（MSE） + L2 正则化</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>compute_loss</span>(X, y, theta, bias, lambda_reg):
</span></span><span style=display:flex><span>    n_samples <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>    predictions <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(X, theta) <span style=color:#f92672>+</span> bias
</span></span><span style=display:flex><span>    mse_loss <span style=color:#f92672>=</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>/</span> (<span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> n_samples)) <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>sum((predictions <span style=color:#f92672>-</span> y) <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>    l2_penalty <span style=color:#f92672>=</span> (lambda_reg <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>) <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>sum(theta <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span>)  <span style=color:#75715e># 正则化项</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> mse_loss <span style=color:#f92672>+</span> l2_penalty
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 梯度更新</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>compute_gradients</span>(X, y, theta, bias, lambda_reg):
</span></span><span style=display:flex><span>    n_samples <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>    predictions <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(X, theta) <span style=color:#f92672>+</span> bias
</span></span><span style=display:flex><span>    error <span style=color:#f92672>=</span> predictions <span style=color:#f92672>-</span> y
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 梯度计算 包含 L2 惩罚</span>
</span></span><span style=display:flex><span>    d_theta <span style=color:#f92672>=</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>/</span> n_samples) <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>dot(X<span style=color:#f92672>.</span>T, error) <span style=color:#f92672>+</span> lambda_reg <span style=color:#f92672>*</span> theta
</span></span><span style=display:flex><span>    d_bias <span style=color:#f92672>=</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>/</span> n_samples) <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>sum(error)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> d_theta, d_bias
</span></span></code></pre></div></li></ul><hr><h3 id=l1-正则化l1-regularization><strong>L1 正则化（L1 Regularization）</strong>
<a class=anchor href=#l1-%e6%ad%a3%e5%88%99%e5%8c%96l1-regularization>#</a></h3><p>L1 正则化（Lasso 正则化）通过在损失函数中添加权重绝对值和的惩罚项，限制模型参数的大小，同时可以实现特征选择的作用。公式如下：
<span>\[
J(\theta) = Loss(\theta) + \lambda\lVert \theta \rVert_{1} = Loss(\theta) + \lambda \sum_{i=1}^n |\theta_i|
\]</span></p><ul><li><span>\(\lambda\)
</span>：正则化强度，权衡损失函数与正则化项的重要性。</li><li><span>\(\sum_{i=1}^n |\theta_i|\)
</span>：模型权重的 L1 范数（曼哈顿范数）。</li></ul><div align=center><img src=/images/l1.png width=400px/></div><p>优化参数 <span>\(\theta\)
</span>时，我们对目标函数 <span>\(J(\theta) \)
</span>关于 <span>\(\theta\)
</span>求偏导：</p><span>\[
\frac{\partial J(\theta)}{\partial \theta_i} = \nabla J(\theta_i) + \lambda \cdot \text{sign}(\theta_i)
\]</span><p>其中 <span>\(\text{sign}(\theta_i)\)
</span>是符号函数，定义为：
<span>\[
\text{sign}(\theta_i) =
\begin{cases}
1, & \text{if } \theta_i > 0 \\
-1, & \text{if } \theta_i < 0 \\
0, & \text{if } \theta_i = 0
\end{cases}
\]</span></p><p>参数更新规则（梯度下降法）为：
<span>\[
\theta := \theta - \alpha \left( \nabla J(\theta) + \lambda \cdot \text{sign}(\theta) \right)
\]</span></p><ul><li><strong>L1 正则化的优点</strong>：<ol><li><strong>特征选择功能</strong>：L1 正则化会将部分<strong>不重要的特征权重缩小到 0</strong>，从而直接移除这些特征。对于高维稀疏数据（如文本分类、基因数据分析）效果显著。</li><li><strong>模型可解释性</strong>: 由于<strong>部分权重为 0</strong>，模型变得更加简洁，方便解读哪些特征对预测结果最重要。</li></ol></li><li><strong>L1 正则化的缺点</strong>:<ol><li>参数稀疏性可能<strong>损失重要信息</strong>: 对于相关性较高的特征，L1 可能随机选择部分特征置零，而丢失其他有价值的信息。</li><li>优化复杂性: L1 正则化的目标函数由于<strong>绝对值的非连续性</strong>，可能在<strong>优化时收敛较慢</strong>。</li></ol></li><li><strong>L1 正则化的适用场景</strong>:<ol><li><strong>高维稀疏数据</strong>: 如文本分类或图像处理中的稀疏特征。</li><li>需要特征选择: 适合在数据预处理阶段对<strong>重要特征进行筛选</strong>。</li></ol></li><li><strong>L1 正则化代码实现</strong><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># &lt;--- From scratch ---&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 损失函数：均方误差（MSE） + L1 正则化</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>compute_loss</span>(X, y, theta, bias, lambda_reg):
</span></span><span style=display:flex><span>    n_samples <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>    predictions <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(X, theta) <span style=color:#f92672>+</span> bias
</span></span><span style=display:flex><span>    mse_loss <span style=color:#f92672>=</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>/</span> (<span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> n_samples)) <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>sum((predictions <span style=color:#f92672>-</span> y) <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>    l1_penalty <span style=color:#f92672>=</span> lambda_reg <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>sum(np<span style=color:#f92672>.</span>abs(theta))  <span style=color:#75715e># 正则化项（L1 范数）</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> mse_loss <span style=color:#f92672>+</span> l1_penalty
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 梯度更新</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>compute_gradients</span>(X, y, theta, bias, lambda_reg):
</span></span><span style=display:flex><span>    n_samples <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>    predictions <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(X, theta) <span style=color:#f92672>+</span> bias
</span></span><span style=display:flex><span>    error <span style=color:#f92672>=</span> predictions <span style=color:#f92672>-</span> y
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 梯度计算 包含 L1 惩罚</span>
</span></span><span style=display:flex><span>    d_theta <span style=color:#f92672>=</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>/</span> n_samples) <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>dot(X<span style=color:#f92672>.</span>T, error) <span style=color:#f92672>+</span> lambda_reg <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>sign(theta)
</span></span><span style=display:flex><span>    d_bias <span style=color:#f92672>=</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>/</span> n_samples) <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>sum(error)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> d_theta, d_bias
</span></span></code></pre></div></li></ul><hr><h2 id=数据增强dataset-augmentation><strong>数据增强（Dataset Augmentation）</strong>
<a class=anchor href=#%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%badataset-augmentation>#</a></h2><p>数据增强是一种通过<strong>对原始数据进行变换或扩展，生成额外的训练样本</strong>的方法，旨在提升模型的鲁棒性和泛化能力。它在训练数据不足、分布偏差或过拟合等问题上尤为有效，特别是在深度学习任务（如计算机视觉和自然语言处理）中，数据增强常被用作关键的预处理技术。数据增强的核心目的有：</p><ol><li><strong>增加数据多样性</strong>：在保持原始数据标签不变的前提下，生成不同的样本，<strong>模拟现实中数据的潜在变化</strong>。</li><li><strong>减少过拟合风险</strong>：通过<strong>增加训练样本</strong>，降低模型对原始训练数据的记忆，提高模型的泛化性能。</li><li><strong>提升模型鲁棒性</strong>：让模型更好地<strong>适应数据的扰动和不确定性</strong>，例如噪声或旋转等变化。</li></ol><h3 id=图像数据增强><strong>图像数据增强</strong>
<a class=anchor href=#%e5%9b%be%e5%83%8f%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba>#</a></h3><p>图像数据增强方法通常直接作用于图像像素，以生成不同变体。常见技术包括：</p><ul><li><strong>几何变换</strong>：旋转（Rotation），翻转（Flip），缩放（Scaling），平移（Translation），剪裁（Cropping）。</li><li><strong>颜色变换</strong>：亮度调整（Brightness Adjustment），对比度调整（Contrast Adjustment），色调调整（Hue Adjustment），饱和度调整（Saturation Adjustment）。</li><li><strong>添加噪声</strong>：高斯噪声（Gaussian Noise），盐噪声与椒噪声（Salt-and-Pepper Noise）。</li></ul><h3 id=文本数据增强><strong>文本数据增强</strong>
<a class=anchor href=#%e6%96%87%e6%9c%ac%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba>#</a></h3><p>文本数据的增强方法相较于图像更加复杂，因为文本的语法和语义需要保持一致。常用技术包括：</p><ul><li><strong>同义词替换（Synonym Replacement）</strong>：替换文本中部分单词为同义词，例如将 “happy” 替换为 “joyful”。</li><li><strong>随机插入（Random Insertion）</strong>：向句子中随机插入同义词或相关词汇。</li><li><strong>随机删除（Random Deletion）</strong>：随机删除句子中的某些单词。</li><li><strong>回译（Back Translation）</strong>：将句子翻译成另一种语言，再翻译回原语言，生成语义一致但表述不同的句子。</li><li><strong>句法变换（Syntactic Transformations）</strong>：改变句子的语法结构，例如主动语态转被动语态。</li></ul><h3 id=时间序列数据增强><strong>时间序列数据增强</strong>
<a class=anchor href=#%e6%97%b6%e9%97%b4%e5%ba%8f%e5%88%97%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba>#</a></h3><p>针对时间序列数据（如音频信号、传感器数据、股票数据等），常用方法包括：</p><ul><li><strong>随机噪声（Random Noise）</strong>：在时间序列信号中加入少量随机噪声。</li><li><strong>时间偏移（Time Shifting）</strong>：将时间序列信号整体向前或向后移动。</li><li><strong>插值与采样（Interpolation and Sampling）</strong>：对原始序列进行上下采样或插值。</li><li><strong>窗口切片（Window Slicing）</strong>：随机选择时间序列的一部分作为新样本。</li></ul><hr><h2 id=噪声注入noise-injection><strong>噪声注入（Noise Injection）</strong>
<a class=anchor href=#%e5%99%aa%e5%a3%b0%e6%b3%a8%e5%85%a5noise-injection>#</a></h2><p>Noise Injection 是一种在机器学习模型训练过程中<strong>有意加入噪声</strong>的技术，旨在增强模型的鲁棒性、泛化能力以及避免过拟合。噪声注入的核心思想是通过扰动输入数据、模型参数、或隐藏层的激活值，使<strong>模型更能适应训练数据中的噪声和不确定性</strong>，从而提高其对真实数据的适应能力。</p><h3 id=常见的噪声注入方法><strong>常见的噪声注入方法</strong>
<a class=anchor href=#%e5%b8%b8%e8%a7%81%e7%9a%84%e5%99%aa%e5%a3%b0%e6%b3%a8%e5%85%a5%e6%96%b9%e6%b3%95>#</a></h3><ol><li><strong>输入数据中的噪声注入</strong>：在训练过程中，直接对输入数据进行扰动。例如：<ul><li><strong>对数值型输入数据添加随机噪声</strong>：
<span>\[
x' = x + \mathcal{N}(0, \sigma^2)
\]
</span>其中，<span>
\(\mathcal{N}(0, \sigma^2)\)
</span>是均值为 0，方差为 <span>\(\sigma^2\)
</span>的高斯噪声。</li><li><strong>对图像数据应用随机变换</strong>，例如：<ul><li>随机裁剪、旋转、翻转、亮度调节等。</li><li>使用像素级别的随机扰动（例如，加盐噪声或椒盐噪声）。</li></ul></li><li><strong>作用</strong>：<ul><li>使模型更能适应输入数据的多样性，降低过拟合风险。</li><li>提升对输入<strong>数据中的小扰动（如测量误差）的鲁棒性</strong>。</li></ul></li></ul></li><li><strong>参数中的噪声注入</strong>：对模型的参数（例如权重）添加随机噪声：<ul><li><strong>对参数添加噪声</strong>：在<strong>每次梯度更新后</strong>，对模型的权重或偏置值添加噪声：
<span>\[
W' = W + \mathcal{N}(0, \sigma^2)
\]</span></li><li><strong>作用</strong>：<ul><li>防止模型<strong>权重过度依赖某些特定的参数值</strong>。</li><li>增强模型对权重初始化的鲁棒性。</li></ul></li></ul></li></ol><blockquote class="book-hint warning"><p><strong>Note：</strong> <strong>参数中的噪声注入</strong> 直接作用在<strong>模型的参数上</strong>，通常是权重更新过程中加入的随机扰动，<strong>改变了参数的优化路径</strong>，使得训练过程更加稳健。</p><p>而<strong>隐藏层中的噪声注入</strong>，噪声被<strong>直接加入到隐藏层的激活值（神经元的输出）中</strong>，会使得每一次前向传播的输出不同，但不改变权重值本身，从而增强模型对输入数据的变化或中间表示不确定性的鲁棒性。</p></blockquote><ol start=3><li><strong>隐藏层中的噪声注入</strong>：在神经网络的<strong>隐藏层中对激活值进行随机扰动</strong>：<ul><li><strong>Dropout</strong> 是一种常用的噪声注入方法，在每次前向传播时，随机将隐藏层的某些神经元置为 0（断开连接），以防止神经网络对特定神经元的过度依赖。详见 <a href=/docs/machine-learning/regularization/#dropout>Dropout</a></li><li><strong>添加噪声</strong>：在隐藏层激活值中加入高斯噪声：
<span>\[
h{\prime} = h + \mathcal{N}(0, \sigma^2)
\]</span></li><li><strong>作用</strong>：<ul><li>加入随机噪声可以<strong>模拟训练中的不确定性</strong>，使模型更加稳健。</li></ul></li></ul></li><li><strong>标签中的噪声注入</strong>: 有时也会对标签进行扰动（Label Smoothing）：<ul><li>将离散标签的 “硬边界” 分布转化为 “软边界” 分布，例如，将类别标签从 <code>[0, 1]</code> 转变为 <code>[0.1, 0.9]</code>。</li><li><strong>作用</strong>：<ul><li>防止模型对训练数据中的标签过于自信（即减少过拟合）。</li><li>提升模型对噪声标签的鲁棒性。</li></ul></li></ul></li></ol><hr><h2 id=正则化在神经网络中的应用><strong>正则化在神经网络中的应用</strong>
<a class=anchor href=#%e6%ad%a3%e5%88%99%e5%8c%96%e5%9c%a8%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e4%b8%ad%e7%9a%84%e5%ba%94%e7%94%a8>#</a></h2><hr><h3 id=weight-decay><strong>Weight Decay</strong>
<a class=anchor href=#weight-decay>#</a></h3><p>Weight Decay 是一种用于正则化机器学习模型的技术，其核心思想是通过向<strong>损失函数中添加正则化项</strong>来约束模型权重的大小，从而防止过拟合。它的本质是 <strong>L2 正则化</strong> 的一种实现方式。Weight Decay 的目标是减少模型权重过大的情况，这样可以使模型更加简单、泛化能力更强。通过在优化过程中对<strong>权重进行衰减（decay）</strong>，限制其无限增大。引入 Weight Decay 后，损失函数为：
<span>\[
L_{\text{total}}(\theta) = \frac{1}{N} \sum_{i=1}^N \mathcal{L}(f(x_i; \theta), y_i) + \lambda \|\theta\|_2^2
\]
</span>其中：</p><ul><li><span>\(\mathcal{L}(\cdot)\)
</span>：是预测值和真实值之间的损失（例如均方误差或交叉熵）。</li><li><span>\(\|\theta\|_{2}^2 = \sum_{j=1}^m \theta_j^2\)
</span>：表示所有权重参数的平方和（即 L2 范数的平方）。</li><li><span>\(\lambda\)
</span>：正则化系数（Weight Decay 参数），控制权重的惩罚力度。</li></ul><p>在优化过程中，<strong>Weight Decay 实现了以下更新规则</strong>：
<span>\[
\theta_{t+1} = \theta_t - \eta \frac{\partial L}{\partial \theta_t} - \eta \lambda \theta_t
\]</span></p><blockquote class="book-hint warning"><p><strong>Note：</strong> Weight Decay 是 L2 正则化的具体实现，但在优化器实现时，它<strong>直接作用于梯度更新规则</strong>，而<strong>不需要显式地将正则化项加到损失函数中</strong>。两者的<strong>效果基本等价</strong>，但 Weight Decay 的实现方式更简洁，适合深度学习优化器的需求。</p></blockquote><ul><li><strong>Weight Decay 代码实现</strong><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># &lt;--- From Pytorch ---&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.optim <span style=color:#66d9ef>as</span> optim
</span></span><span style=display:flex><span><span style=color:#75715e># 模型定义</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># 损失函数</span>
</span></span><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>MSELoss()
</span></span><span style=display:flex><span><span style=color:#75715e># 优化器</span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> optim<span style=color:#f92672>.</span>SGD(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>, weight_decay<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>)
</span></span></code></pre></div></li></ul><hr><h3 id=early-stopping><strong>Early Stopping</strong>
<a class=anchor href=#early-stopping>#</a></h3><p>Early Stopping 是一种防止模型过拟合的正则化方法。通过在<strong>验证集性能不再提升时提前终止训练</strong>，可以有效减少模型的过拟合并提高泛化能力。它的工作原理是：</p><ol><li><strong>分割数据集</strong>：将数据集划分为训练集、验证集 和测试集。</li><li><strong>训练监控</strong>：在训练过程中，<strong>同时监控训练损失和验证损失</strong>。通常，随着训练的进行：<ul><li>训练损失持续降低。</li><li>验证损失先降低，随后可能开始上升（表示过拟合）。</li></ul></li><li><strong>停止条件</strong>：<ul><li>当验证损失<strong>连续多个 epoch 不再降低</strong>（或验证性能不再提升）时，提前终止训练。</li><li>模型停止在<strong>验证性能最佳</strong>的那一刻，而不是继续训练到指定的最大 epoch 数。</li></ul></li></ol><p><strong>关键步骤</strong>：</p><ol><li><strong>监控指标</strong>：通常监控验证损失（如均方误差、交叉熵损失等）。</li><li><strong>耐心（Patience）机制</strong>：如果验证损失在设定的耐心步数（patience steps）内没有改善，停止训练。</li><li><strong>保存最佳模型</strong>：在每次验证性能提升时<strong>保存当前模型的参数（checkpoint）</strong>。训练结束时，<strong>恢复到性能最佳时的模型</strong>。</li></ol><ul><li><strong>Weight Decay 代码实现</strong><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># &lt;--- From Pytorch ---&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Early_Stopping</span>:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, patience<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, delta<span style=color:#f92672>=</span><span style=color:#ae81ff>0.0</span>, path<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;checkpoint.pt&#39;</span>, verbose<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        参数：
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        - patience: 允许验证损失不降低的连续 epoch 数
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        - delta: 最小的验证损失降低幅度，避免浮动引起的误判
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        - path: 保存最佳模型的文件路径
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        - verbose: 是否输出日志信息
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>patience <span style=color:#f92672>=</span> patience
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>delta <span style=color:#f92672>=</span> delta
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>path <span style=color:#f92672>=</span> path
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>verbose <span style=color:#f92672>=</span> verbose
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>counter <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>best_loss <span style=color:#f92672>=</span> float(<span style=color:#e6db74>&#39;inf&#39;</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>early_stop <span style=color:#f92672>=</span> <span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __call__(self, val_loss, model):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> val_loss <span style=color:#f92672>&lt;</span> self<span style=color:#f92672>.</span>best_loss <span style=color:#f92672>-</span> self<span style=color:#f92672>.</span>delta:
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>best_loss <span style=color:#f92672>=</span> val_loss
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>counter <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>save_checkpoint(val_loss, model)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>count <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>counter <span style=color:#f92672>&gt;=</span> self<span style=color:#f92672>.</span>patience:
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>early_stop <span style=color:#f92672>=</span> <span style=color:#66d9ef>True</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>save_checkpoint</span>(self, val_loss, model):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;保存当前最佳模型&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>verbose:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Validation loss improved to </span><span style=color:#e6db74>{</span>val_loss<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>. Saving model...&#34;</span>)
</span></span><span style=display:flex><span>        torch<span style=color:#f92672>.</span>save(model<span style=color:#f92672>.</span>state_dict(), self<span style=color:#f92672>.</span>path)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> SimpleModel(input_dim<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>MSELoss()
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> optim<span style=color:#f92672>.</span>Adam(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># 实例化 Early Stopping</span>
</span></span><span style=display:flex><span>early_stopping <span style=color:#f92672>=</span> EarlyStopping(patience<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, verbose<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, path<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;best_model.pt&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 训练循环</span>
</span></span><span style=display:flex><span>num_epochs <span style=color:#f92672>=</span> <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(num_epochs):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 训练阶段</span>
</span></span><span style=display:flex><span>    model<span style=color:#f92672>.</span>train()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> batch_X, batch_y <span style=color:#f92672>in</span> train_loader:
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>zero_grad()
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(batch_X)
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, batch_y)
</span></span><span style=display:flex><span>        loss<span style=color:#f92672>.</span>backward()
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>step()
</span></span><span style=display:flex><span>    <span style=color:#75715e># 验证阶段</span>
</span></span><span style=display:flex><span>    model<span style=color:#f92672>.</span>eval()
</span></span><span style=display:flex><span>    val_loss <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.0</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>with</span> torch<span style=color:#f92672>.</span>no_grad():
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> batch_X, batch_y <span style=color:#f92672>in</span> val_loader:
</span></span><span style=display:flex><span>            outputs <span style=color:#f92672>=</span> model(batch_X)
</span></span><span style=display:flex><span>            loss <span style=color:#f92672>=</span> criterion(outputs, batch_y)
</span></span><span style=display:flex><span>            val_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    val_loss <span style=color:#f92672>/=</span> len(val_loader)
</span></span><span style=display:flex><span>    <span style=color:#75715e># 调用 Early Stopping</span>
</span></span><span style=display:flex><span>    early_stopping(val_loss, model)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 判断是否停止训练</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> early_stopping<span style=color:#f92672>.</span>early_stop:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;Early stopping triggered. Restoring the best model...&#34;</span>)
</span></span><span style=display:flex><span>        model<span style=color:#f92672>.</span>load_state_dict(torch<span style=color:#f92672>.</span>load(<span style=color:#e6db74>&#39;best_model.pt&#39;</span>))
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>break</span>
</span></span></code></pre></div></li></ul><hr><h3 id=dropout><strong>Dropout</strong>
<a class=anchor href=#dropout>#</a></h3><p>Dropout 是一种广泛用于深度学习的正则化技术，旨在通过减少神经网络的过拟合来提高模型的泛化能力。它的核心思想是在训练过程中<strong>随机地“丢弃”一些神经元</strong>，使得网络在<strong>每一次前向传播和反向传播中都使用不同的结构</strong>。这种随机性<strong>强迫网络在不同的子网络上训练</strong>，从而增强其鲁棒性。</p><div align=center><img src=/images/dropout.png width=450px/></div><ol><li><strong>训练阶段</strong>：<ul><li>对于每一层的每个神经元，按照一个固定的概率 <span>\(p\)
</span>（通常在 0.5 左右）随机将其“丢弃”。</li><li>被丢弃的神经元<strong>不会参与前向传播和反向传播</strong>，其输出被设置为 0。</li><li>未被丢弃的神经元的输出会被放大为 <span>\(\frac{1}{1-p}\)
</span>倍，以保持激活值的期望不变。</li></ul></li><li><strong>测试阶段</strong>：<ul><li><strong>Dropout 不会应用在测试阶段</strong>，因为网络需要全量的神经元进行预测。</li><li>为了与训练阶段保持一致，神经元的输出按比例缩放，即保持其原始激活值。</li></ul></li></ol><p><strong>为什么 Dropout 有效？</strong></p><ol><li><strong>防止过拟合</strong>：<ul><li>Dropout 强迫网络<strong>不会过分依赖某些特定的神经元或路径</strong>，而是学会利用多个不同的路径。</li><li>通过这种方式，网络在面对噪声或新数据时更具鲁棒性。</li></ul></li><li><strong>类似于模型集成</strong>：<ul><li>训练时，Dropout 在每次训练的前向传播中随机丢弃一些神经元，<strong>等价于在每次迭代中训练一个从完整网络中抽取的“子网络”。不同的“子网络”共享参数并被优化，最终可以看作是训练了大量的子模型</strong>。<ul><li>每次迭代训练的是网络的一个随机子集，相当于训练了一些弱模型。</li></ul></li><li>测试时，因为 Dropout 在训练时让模型学到了很多不同的权重组合和特征表示，所以即使在测试时每次计算时都用到了完整的神经元结构，最终的预测也会<strong>综合了所有子网络可能学习到的信息</strong>。<strong>通过对所有神经元的输出进行缩放（保留激活值的期望不变），等价于对所有训练过的子网络的预测进行平均</strong>。<ul><li>训练时，丢弃掉的神经元会导致模型在每次训练时只用到部分神经元，<strong>因此每个神经元的输出会被缩小</strong>，它的输出期望值等于 <span>\(1 - p\)
</span>。</li><li>在测试时，Dropout 不再丢弃任何神经元，所有的神经元都参与计算。为了保持 训练时和测试时的输出期望一致，我们需要在测试时对<strong>每个神经元的输出进行缩放</strong>。缩放因子是 (<span>
\(1 - p\)
</span>) ，因为训练时每个神经元输出的期望是 <span>\((1 - p) \cdot x\)
</span>，我们通过缩放使得测试时的输出期望保持一致。</li></ul></li></ul></li></ol><ul><li><p><strong>Dropout 代码实现</strong></p><p>在 PyTorch 中，神经网络模型有两种模式：训练模式（<code>training</code>）和推理模式（<code>evaluation</code>）。可以通过 <code>model.train()</code> 和 <code>model.eval()</code> 来切换模型的模式。<strong>在训练时，<code>Dropout</code> 会启用，而在推理时，<code>Dropout</code> 会禁用并自动调整输出。</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># &lt;--- From Pytorch ---&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 定义一个简单的神经网络，包含一个 Dropout 层</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>SimpleNN</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, p<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>):
</span></span><span style=display:flex><span>        super(SimpleNN, self)<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>fc1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>50</span>)  <span style=color:#75715e># 输入层到隐藏层</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>fc2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>50</span>, <span style=color:#ae81ff>1</span>)   <span style=color:#75715e># 隐藏层到输出层</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dropout <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Dropout(p)  <span style=color:#75715e># Dropout 层，丢弃概率为 p</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>fc1(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>relu(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>dropout(x)  <span style=color:#75715e># 在激活之后应用 Dropout</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>fc2(x)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> x
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 创建一个简单的神经网络实例</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> SimpleNN(p<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 训练模式</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>train()
</span></span><span style=display:flex><span>input_data <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>32</span>, <span style=color:#ae81ff>10</span>)  <span style=color:#75715e># 假设输入有32个样本，每个样本有10个特征</span>
</span></span><span style=display:flex><span>output_train <span style=color:#f92672>=</span> model(input_data)   <span style=color:#75715e># 训练时，Dropout 会被应用</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 推理模式</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>eval()  <span style=color:#75715e># 切换到推理模式</span>
</span></span><span style=display:flex><span>output_eval <span style=color:#f92672>=</span> model(input_data)   <span style=color:#75715e># 推理时，Dropout 会被禁用</span>
</span></span></code></pre></div></li></ul><hr><h3 id=batch-normalization><strong>Batch Normalization</strong>
<a class=anchor href=#batch-normalization>#</a></h3><p>Batch Normalization (BN) 是一种深度学习中常用的<strong>正则化和加速训练</strong>的方法，最早由 Sergey Ioffe 和 Christian Szegedy 在 2015 年提出。其主要目的是通过减少输入特征的分布变化（Internal Covariate Shift）来稳定训练过程，并加快神经网络的收敛速度。</p><p>Batch Normalization 在<strong>每一层网络的激活值（或输入特征）上进行归一化</strong>。通过对小批量数据（Batch）的统计信息进行归一化，将激活值标准化为具有零均值和单位方差的分布，同时<strong>保留一个可学习的缩放参数和偏移参数来恢复</strong>模型的表达能力。它的公式可以表达为：</p><ol><li><p><strong>计算 Batch 均值和方差</strong>：对当前小批量的输入 <span>\(\mathbf{x} = [x_1, x_2, \ldots, x_m]\)
</span>计算均值和方差：
<span>\[
\mu_B = \frac{1}{m} \sum_{i=1}^m x_i, \quad \sigma_B^2 = \frac{1}{m} \sum_{i=1}^m (x_i - \mu_B)^2
\]
</span>其中 <span>\(m\)
</span>是 batch 的大小。</p></li><li><p><strong>归一化</strong>：使用均值和方差对输入进行标准化：
<span>\[
\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}
\]
</span>其中 <span>\(\epsilon\)
</span>是一个很小的值，用于避免分母为零。</p></li><li><p><strong>缩放和平移</strong>：为了保留模型的表达能力，引入两个可学习参数：缩放参数 <span>\(\gamma\)
</span>和偏移参数 <span>\(\beta\)
</span>。归一化后，输出为：
<span>\[
y_i = \gamma \hat{x}_i + \beta
\]
</span>这里，<span>
\(\gamma\)
</span>和 <span>\(\beta\)
</span>通过反向传播学习（<span>
\(\frac{\partial L}{\partial \gamma}\)
</span>, <span>\(\frac{\partial L}{\partial \beta}\)
</span>），可以调整标准化后的分布，使其适应当前任务。优化器（如 SGD、Adam）会根据学习率和梯度更新 <span>\(\gamma\)
</span>和 <span>\(\beta\)
</span>：</p><p>虽然归一化操作能稳定训练，但直接使用这种标准化后的数据可能会<strong>限制模型的表达能力</strong>。例如，某些任务可能需要激活值在特定范围，而不是被严格限制在零均值和单位方差。缩放和平移允许 BN 后的数据分布与任务需求一致，而<strong>不仅仅局限于零均值单位方差</strong>。</p></li></ol><p><strong>它的作用有：</strong></p><ol><li><strong>加速训练</strong>：归一化使得<strong>梯度传播更加平滑</strong>，减少了梯度爆炸或消失问题，使得训练可以使用更高的学习率，加快收敛速度。</li><li><strong>正则化效果</strong>：小批量数据的均值和方差会产生一定的随机性，这种扰动类似于 Dropout 的正则化效果，有助于减少过拟合。<ul><li><strong>不同小批量会导致略微不同的归一化结果，产生了噪声</strong>。这种随机性迫使模型不能过分依赖特定特征或特定路径，对训练数据的微小变化（如噪声或扰动）不敏感，从而<strong>降低了过拟合风险</strong>。</li></ul></li><li><strong>更深的网络更稳定</strong>：BN 的引入让深度模型（如 ResNet 等）更容易训练，避免梯度消失和参数更新不稳定的问题。<ul><li>由于每一层的输入在每个小批量上被归一化，<strong>模型在训练时变得更加稳定</strong>。</li></ul></li></ol><blockquote class="book-hint warning"><p><strong>Note：</strong> 通常在<strong>线性变换之后</strong>、<strong>激活函数之前</strong>使用 Batch Normalization。</p></blockquote><p>Batch Normalization <strong>在优化（Optimization）问题上的具体细节</strong>详见 <a href=../optimization/#%e6%89%b9%e9%87%8f%e6%a0%87%e5%87%86%e5%8c%96batch-normalization>优化章节的 Batch Normalization</a>。</p><ul><li><strong>Batch Normalization 代码实现</strong><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># &lt;--- From Pytorch ---&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 定义模型</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>ModelWithBN</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self):
</span></span><span style=display:flex><span>        super(ModelWithBN, self)<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>fc1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>bn1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>BatchNorm1d(num_features<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>)  <span style=color:#75715e># Batch Normalization</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>fc2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>50</span>, <span style=color:#ae81ff>20</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>bn2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>BatchNorm1d(num_features<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>)  <span style=color:#75715e># Batch Normalization</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>relu <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>ReLU()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>relu(self<span style=color:#f92672>.</span>bn1(self<span style=color:#f92672>.</span>fc1(x)))
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>relu(self<span style=color:#f92672>.</span>bn2(self<span style=color:#f92672>.</span>fc2(x)))
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> x
</span></span></code></pre></div><blockquote><p><strong>Note</strong>: <span>\(\gamma\)
</span>和 <span>\(\beta\)
</span>在 <code>BatchNorm</code> 中<strong>自动管理</strong>。</p></blockquote></li></ul><hr><h2 id=集成学习算法ensemble-methods><strong>集成学习算法（Ensemble Methods）</strong>
<a class=anchor href=#%e9%9b%86%e6%88%90%e5%ad%a6%e4%b9%a0%e7%ae%97%e6%b3%95ensemble-methods>#</a></h2><p>详见 <a href=ensemble-methods.md>集成学习算法</a>。</p><hr><h2 id=对抗训练adversarial-training><strong>对抗训练（Adversarial Training）</strong>
<a class=anchor href=#%e5%af%b9%e6%8a%97%e8%ae%ad%e7%bb%83adversarial-training>#</a></h2><p>Adversarial Training（对抗训练）是一种增强模型鲁棒性、提升其对抗样本（adversarial examples）抵抗力的训练方法。在深度学习中，<strong>对抗样本是经过精心设计，旨在迷惑模型的输入数据</strong>。对抗训练通过将这些对抗样本添加到训练集中，使得模型在学习过程中能够处理这些干扰并增强其泛化能力。</p><div align=center><img src=/images/AdversarialTraining.png width=600px/></div><h3 id=对抗样本的概念><strong>对抗样本的概念</strong>
<a class=anchor href=#%e5%af%b9%e6%8a%97%e6%a0%b7%e6%9c%ac%e7%9a%84%e6%a6%82%e5%bf%b5>#</a></h3><p>对抗样本是指那些通过对原始输入数据添加<strong>微小但精心设计的扰动（通常是通过优化算法生成）</strong>，使得模型产生错误预测的数据点。尽管<strong>这些扰动对于人眼来说几乎不可察觉</strong>，但却能够显著改变模型的输出。</p><p><strong>举个例子</strong>：假设我们训练一个图片分类模型，模型可能把一张猫的图片正确分类为“猫”。但通过对图片添加微小的噪声，模型可能将其错误分类为“狗”。这个微小的噪声就是对抗样本。</p><blockquote class="book-hint warning"><p><strong>Note：</strong> <strong>Adversarial Training 中的噪声</strong>是 针对模型的弱点设计的对抗噪声。这些噪声是通过优化过程生成的，目的是让模型在对抗样本中犯错。因此，<strong>噪声的设计是 精心的、具体的，每个样本的扰动都是有目的地</strong>用来欺骗模型的。</p><p><strong>Noise Injection 中的噪声</strong>通常是 <strong>随机的、不具目标性</strong>，并不是有意识地去迷惑模型。它通常是简单的随机噪声，直接加到输入数据、隐藏层或权重中。其目的是通过扰动来防止模型过拟合，提高模型的泛化能力。</p></blockquote><h3 id=对抗训练的过程><strong>对抗训练的过程</strong>
<a class=anchor href=#%e5%af%b9%e6%8a%97%e8%ae%ad%e7%bb%83%e7%9a%84%e8%bf%87%e7%a8%8b>#</a></h3><p>在对抗训练中，我们通过以下步骤来训练模型，使其对抗样本具有鲁棒性：</p><ol><li><p><strong>生成对抗样本</strong>：首先，生成对抗样本。对抗样本是通过对输入数据施加一定的扰动使得模型产生错误预测。常见的生成对抗样本的方法包括：</p><ul><li><strong>Fast Gradient Sign Method (FGSM)</strong>：使用模型的梯度信息来生成对抗样本。通过计算损失函数对输入数据的梯度，并按梯度方向添加一个小的扰动。在<strong>每一次正向传播（Forward Pass）和反向传播（Backward Pass）后，计算损失函数相对于输入样本 <span>\(x\)
</span>的梯度</strong>，即 <span>\(\nabla_x \mathcal{L}(\theta, x, y)\)
</span>，根据计算得到的输入梯度，通过扰动样本 <span>\(x\)
</span>来生成对抗样本 <span>\(x_{\text{adv}}\)
</span>：
<span>\[
x_{\text{adv}} = x + \epsilon \cdot \text{sign}(\nabla_x \mathcal{L}(\theta, x, y))
\]
</span>其中， <span>\(\epsilon\)
</span>是扰动的大小，通常是一个小的常数，控制扰动的幅度。</li></ul></li><li><p><strong>结合对抗样本与正常样本进行训练</strong>：使用生成的对抗样本 <span>\(x_{\text{adv}}\)
</span>进行正向传播，并计算损失函数。然后使用对抗样本来计算损失函数相对于模型参数的梯度，并进行参数更新。Adversarial Training 的<strong>最终损失函数通常是 原始损失 和 对抗损失 的加权和</strong>。具体的损失函数形式可以写成：
<span>\[
\mathcal{L}_{\text{total}} = \mathbb{E}_{x,y} \left[ \mathcal{L}(\theta, x, y) \right] + \lambda \cdot \mathbb{E}_{x,y} \left[ \mathcal{L}(\theta, x + \delta, y) \right]
\]
</span>其中：</p><ul><li><span>\(\mathcal{L}(\theta, x, y)\)
</span>是标准的原始损失，通常是交叉熵损失（或其他损失函数），用于普通训练样本。</li><li><span>\(\mathcal{L}(\theta, x + \delta, y)\)
</span>是在对抗样本 <span>\(x + \delta\)
</span>上计算的损失。</li><li><span>\(\lambda\)
</span>是一个超参数，用于平衡标准损失和对抗损失的贡献。</li></ul></li><li><p><strong>优化训练过程</strong>：通过常规的优化方法（如梯度下降），模型会学习如何在对抗样本中保持较高的准确性。这通常会导致模型对潜在的攻击具有更强的抵抗能力。</p></li></ol></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#参数范数惩罚parameter-norm-penalties><strong>参数范数惩罚（Parameter Norm Penalties）</strong></a><ul><li><a href=#直观理解参数范数正则化的作用><strong>直观理解参数范数正则化的作用</strong></a></li><li><a href=#l2-正则化l2-regularization><strong>L2 正则化（L2 Regularization）</strong></a></li><li><a href=#l1-正则化l1-regularization><strong>L1 正则化（L1 Regularization）</strong></a></li></ul></li><li><a href=#数据增强dataset-augmentation><strong>数据增强（Dataset Augmentation）</strong></a><ul><li><a href=#图像数据增强><strong>图像数据增强</strong></a></li><li><a href=#文本数据增强><strong>文本数据增强</strong></a></li><li><a href=#时间序列数据增强><strong>时间序列数据增强</strong></a></li></ul></li><li><a href=#噪声注入noise-injection><strong>噪声注入（Noise Injection）</strong></a><ul><li><a href=#常见的噪声注入方法><strong>常见的噪声注入方法</strong></a></li></ul></li><li><a href=#正则化在神经网络中的应用><strong>正则化在神经网络中的应用</strong></a><ul><li><a href=#weight-decay><strong>Weight Decay</strong></a></li><li><a href=#early-stopping><strong>Early Stopping</strong></a></li><li><a href=#dropout><strong>Dropout</strong></a></li><li><a href=#batch-normalization><strong>Batch Normalization</strong></a></li></ul></li><li><a href=#集成学习算法ensemble-methods><strong>集成学习算法（Ensemble Methods）</strong></a></li><li><a href=#对抗训练adversarial-training><strong>对抗训练（Adversarial Training）</strong></a><ul><li><a href=#对抗样本的概念><strong>对抗样本的概念</strong></a></li><li><a href=#对抗训练的过程><strong>对抗训练的过程</strong></a></li></ul></li></ul></nav></div></aside></main></body></html>