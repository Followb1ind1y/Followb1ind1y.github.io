<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on Followblindly</title><link>http://localhost:52404/tags/machine-learning/</link><description>Recent content in Machine Learning on Followblindly</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 13 May 2021 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:52404/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Linear Regression</title><link>http://localhost:52404/posts/02_linear_regression/</link><pubDate>Sat, 08 May 2021 00:00:00 +0000</pubDate><guid>http://localhost:52404/posts/02_linear_regression/</guid><description>&lt;p>Regression is a method of modelling a target value based on independent predictors. This method is mostly used for forecasting and finding out &lt;strong>cause and effect relationship between variables&lt;/strong>. Regression techniques mostly differ based on the number of independent variables and the type of relationship between the independent and dependent variables. Regression problems usually have one continuous and unbounded dependent variable. The inputs, however, can be continuous, discrete, or even categorical data such as gender, nationality, brand, and so on.&lt;/p></description></item><item><title>Logistic Regression</title><link>http://localhost:52404/posts/03_logistic_regression/</link><pubDate>Tue, 11 May 2021 00:00:00 +0000</pubDate><guid>http://localhost:52404/posts/03_logistic_regression/</guid><description>&lt;p>Binary Logistic Regression is one of the most simple and commonly used Machine Learning algorithms for &lt;strong>two-class classification&lt;/strong>. It is easy to implement and can be used as the baseline for any binary classification problem. Its basic fundamental concepts are also constructive in deep learning. Logistic regression describes and estimates the relationship between one dependent binary variable and independent variables.&lt;/p>
&lt;blockquote>
&lt;p>&amp;ldquo;分类&amp;quot;是应用 &lt;strong>逻辑回归(Logistic Regression)&lt;/strong> 的目的和结果, 但中间过程依旧是&amp;quot;回归&amp;rdquo;. 通过逻辑回归模型, 我们得到的计算结果是0-1之间的连续数字, 可以把它称为&amp;quot;可能性&amp;quot;（概率）. 然后, 给这个可能性加一个阈值, 就成了分类. 例如, 可能性大于 0.5 即记为 1, 可能性小于 0.5 则记为 0.&lt;/p></description></item><item><title>LDA and QDA for Classification</title><link>http://localhost:52404/posts/04_lda_and_qda_for_classification/</link><pubDate>Thu, 13 May 2021 00:00:00 +0000</pubDate><guid>http://localhost:52404/posts/04_lda_and_qda_for_classification/</guid><description>&lt;p>Discriminant analysis encompasses methods that can be used for both classification and dimensionality reduction. &lt;strong>Linear discriminant analysis (LDA)&lt;/strong> is particularly popular because it is both a classifier and a dimensionality reduction technique. Despite its simplicity, LDA often produces robust, decent, and interpretable classification results. When tackling real-world classification problems, LDA is often the first and benchmarking method before other more complicated and flexible ones are employed. &lt;strong>Quadratic discriminant analysis (QDA)&lt;/strong> is a variant of LDA that allows for non-linear separation of data.&lt;/p></description></item></channel></rss>